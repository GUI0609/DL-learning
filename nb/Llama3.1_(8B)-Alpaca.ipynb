{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI9S71rQ3Kby"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayxJBZtt3Kb2"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1eYm90R3Kb3"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXTLDWRi3Kb4"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rDw4w5xa3Kb5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Normally using pip install unsloth is enough\n",
        "\n",
        "# Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n",
        "# Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2jRhKN-3Kb7"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "q-pDY6HK3rT-",
        "outputId": "aeadf060-62d8-419f-8647-7434f36a1e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "d05508998bea4d6389f68a7bcc04050b",
            "5d3a24da4335490aa205ac80324d52f7",
            "6930248394e345f7b130784c04d43341",
            "6a1c0cb8e59e4691944920b05dbff6a1",
            "a71d05451295413488012326297b582e",
            "557c156d617742979302a02a847c59d5",
            "de253d5d3e014395870cfe3c5d31635c",
            "34cd2b677841417e9155086ee4673180",
            "fa9ee2cb238b4a2382e07b4a6a30d7b0",
            "e13634c85a5f471a9dc6eab5584c4f5a",
            "bb8e838720854b49b9b7b6c85493ca96",
            "99d3c17ff5754d329f9d443b70774f74",
            "4b3e9a1964a34ef9bb775a8983c25a56",
            "409e341c45f64b0ea9c6abd60dde4bfb",
            "05404ab82ade48e892aa8832e7144dec",
            "b7f658a74a334bc1a3ec68a4d1fb27b5",
            "7bfca92d3c744f00af8e732017fa9fbe",
            "fcaf15df282841d68749cc5040ea648d",
            "b2174a58002845299b066283ab3d2d8c",
            "35bc5a363e804c79bd16939dbf1ff35b",
            "7a1c806451724933af6dfe9fcc28b7ea",
            "48833bda51fb420888ca817ca9d79c36",
            "53b5e1006c7b4b4e9ffde2c40fcfb920",
            "bc07955dc92d4ab7a9cc25c5e2be31ed",
            "53d48c94a6954779a2679bbf767a95b9",
            "287b4ae6701d4e93a4d36c8f9c2cfc4c",
            "0e60b734371c43eab0c28a76115b3378",
            "b69708334dd24e46913029e5ecb12d96",
            "63462a981a1c46aeb6dc79be659761c3",
            "a981c81081e94657ab780ce1cccdfa5d",
            "3417e82fb6b14a16bfb726b19e364044",
            "101e27567146455d88ca46575e13bdae",
            "6d70d25ce3ce48c6bda6b4c12c91be59",
            "2773929ff3104db78c79ba5d1e536668",
            "3a37e38f774e4d70a3243510ae99c730",
            "15273559898c45aaa6da45274db74c4e",
            "8d00b41544db4b609b4a4f9202fb3ce4",
            "a5dd7d3bef5b4e718dddfd27041688eb",
            "b171569c3e8f4b03bdda824e16b21969",
            "7c44b3feb513484e9dc7bdb887bc123d",
            "282a0b3844d9421b8b7ed0011aeb9de7",
            "dbbce248d1e3452fa012a77a2fd4f6d0",
            "f56bb51759fc41d0bb9dc35035a9cecf",
            "3389a85b593744c880ad399bd2a165af",
            "c944aeb45fdc4f61a8424c4a0f44a8f6",
            "a44daaccd6df4063abbf5b5e18c79ae2",
            "7df7c04604464b638bf3cf534fac913a",
            "0efa81beaf134d25ace6b25e8ae60a8c",
            "931aafc86fde496b98ca64038d3b9a7b",
            "b95e7fd9d87d4f418b90155904c2935d",
            "fffbedd22dbb467eae8f9c05d204c3e7",
            "7353fb15d3d94fa6bd985864d62c6f08",
            "9aabca9a232d4a7c900763fa98e348b1",
            "a4d31dbd19144d88829f50718fc6e097",
            "c4775896274d4a04b1a7f25b157e4d9a"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "cfc98a33-b2c8-439a-b8f9-3de335e431b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d05508998bea4d6389f68a7bcc04050b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99d3c17ff5754d329f9d443b70774f74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53b5e1006c7b4b4e9ffde2c40fcfb920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2773929ff3104db78c79ba5d1e536668"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c944aeb45fdc4f61a8424c4a0f44a8f6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "e0bf29df-240b-448d-f2d3-0ca5adbd6c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.2.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3ÂæÆË∞ÉÂâçÊµãËØï\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "### Input:\n",
        "{}\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"\"\"[Role]: You are an expert in the field of rare disease. You will be provided and asked about a complicated clinical case; read it carefully and then provide a diverse and comprehensive differential diagnosis disease. Please write down the reasoning process, no more than 5 reasoning steps. Let's think step by step.\"\"\", # instruction\n",
        "        'Patients phenotype:Abnormal vertebral morphology, Cutaneous syndactyly, Cerebral atrophy, Short stature, Arthralgia, Hypoplasia of the corpus callosum', # input\n",
        "        \"Multiple epiphyseal dysplasia, Al-Gazali type\", # ÁúüÂÆûËæìÂá∫\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)\n"
      ],
      "metadata": {
        "id": "BMqWAphU4hLV",
        "outputId": "ac01ea7b-8bf9-4958-9382-ee1bce374d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "[Role]: You are an expert in the field of rare disease. You will be provided and asked about a complicated clinical case; read it carefully and then provide a diverse and comprehensive differential diagnosis disease. Please write down the reasoning process, no more than 5 reasoning steps. Let's think step by step.\n",
            "### Input:\n",
            "Patients phenotype:Abnormal vertebral morphology, Cutaneous syndactyly, Cerebral atrophy, Short stature, Arthralgia, Hypoplasia of the corpus callosum\n",
            "### Response:\n",
            "Multiple epiphyseal dysplasia, Al-Gazali type (MED) is a rare genetic disorder that is characterized by abnormalities in the development and structure of the skeletal system, particularly the vertebral column. The patient's phenotype, including abnormal vertebral morphology, cutaneous syndactyly, and short stature, are consistent with this diagnosis.\n",
            "\n",
            "Here are the reasoning steps:\n",
            "\n",
            "1. The patient's abnormal vertebral morphology and short stature are indicative of a skeletal disorder. MED is a known cause of these symptoms.\n",
            "2. The presence of cutaneous syndactyly, a condition in which fingers or toes are webbed, is also a characteristic feature of MED.\n",
            "3. Cerebral at\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Êï∞ÊçÆÊñá‰ª∂/export2.csv')\n",
        "df = df.groupby('d.name')['p.term'].apply(list).reset_index()\n",
        "df['input'] = df['p.term'].apply(lambda row: 'Patients phenotype: '+' '.join(row))\n",
        "df['output'] = df['d.name']\n",
        "df['instruction'] = [\"\"\"[Role]: You are an expert in the field of rare disease. You will be provided and asked about a complicated clinical case; read it carefully and then provide a diverse and comprehensive differential diagnosis disease. Please write down the reasoning process, no more than 5 reasoning steps. Let's think step by step.\"\"\"]*len(df)\n",
        "df = df[['input','output','instruction']]\n",
        "# Â∞ÜDataFrameËΩ¨Êç¢‰∏∫JSONÂ≠óÁ¨¶‰∏≤\n",
        "json_str = df.to_json(orient='records', force_ascii=False)\n",
        "with open('data.json', 'w', encoding='utf-8') as f:\n",
        "    f.write(json_str)\n",
        "    #4ÂáÜÂ§áÂæÆË∞ÉÊï∞ÊçÆÈõÜ\n",
        "from datasets import Dataset, Features, Value, DatasetDict\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # ÂøÖÈ°ªÊ∑ªÂä† EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # ÂøÖÈ°ªÊ∑ªÂä†EOS_TOKENÔºåÂê¶ÂàôÊó†ÈôêÁîüÊàê\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "# dataset = load_dataset(\"v3ucn/chinese-novel-dataset\", split = \"train\")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Âä†ËΩΩJSONÊñá‰ª∂\n",
        "dataset = Dataset.from_json('data.json')\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "1Nx0Zr114pJu",
        "outputId": "9b2e4830-b4ae-44a9-8f55-16143a6f0ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "39330006fe1f411c828b181e570974f3",
            "121631d20ad54400b573be72327a6163",
            "a996ba3ebe674ad68b952582de76608d",
            "d3cff037bd6b4635a64988f33413f350",
            "dcdfe1a778ca4c40b8ed0e3143f78ad7",
            "ee39dcf11fa748e3987ef5e9fdb794ce",
            "479989b277f14246b56f37ad0b06123d",
            "1df3bed2c278472cb044a052ba587d92",
            "a805eb4fd46c4e48856ee100d06e6e86",
            "37bf5d4983494c2cb2b04e5c6807381b",
            "f8974ab5a7d74c3a8422a29fc8755c80",
            "95b18177591f4eef974600f97151b0ee",
            "2db7d0851bc54df1906578cfaf0b368a",
            "ff33be2f36484c64b3d1d38e3405d327",
            "3d3f3bce48ce4bcdb499f3f28c975f94",
            "7216def0fcd947bfac726589cf170116",
            "f9cdf5a8ddb74ccdb52bb6a5b789f2e9",
            "4fcc333e33044c38a804a9054ffbd503",
            "0cf1a8ef845d4224a739d0e7487af946",
            "4f0560006cc04eb696e11fe99721789f",
            "f00bfea975a840d89a471e4bbe9ac6da",
            "849f7342338a41a89169318dd12edb20"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39330006fe1f411c828b181e570974f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95b18177591f4eef974600f97151b0ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bf14bf550b91492e9494315fec9396dd",
            "9edbab43a9b84850979193f47d7784f8",
            "4e8117416a7444ccbd425c616535ac2a",
            "edf468dab1f044b9acaa7f77b6184baf",
            "f9ed5cebdc714be1bf342c9fe8732fc6",
            "79bc8fb260e14ac4a3b8a4f2a39579c9",
            "86b0f908024b40f1ac6efd6bc6a41536",
            "9a7b0af4b5ec4af09f4718c42407cfba",
            "282b2ede643f47cfa4698ed6eacbde7a",
            "b8d6b180a5e140558d69094da7b50b67",
            "0c53f064c945490a95cf329a4f91158c"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "0a1b8a84-3445-4072-a18d-01c6075d651c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/4240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf14bf550b91492e9494315fec9396dd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 32,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 250,\n",
        "        learning_rate = 5e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "bf6fb5cf-0c06-4647-e6e8-2745ba3ad786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.838 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "b4641db5-dd2d-4022-b3a6-7d83658a2af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 4,240 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 250\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 19:23, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.160200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.808800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.054100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.788500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.056100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.696600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4.210100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.228700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3.908400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3.922500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3.939700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>3.666500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.897800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>3.638200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>3.684100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>4.155700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>4.142200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>3.890600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>3.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>3.890800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>4.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>4.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>3.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>4.104700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>3.652000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>4.052600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.014300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>4.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>3.793700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>4.039700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>4.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>3.744600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>3.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>3.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>3.732800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>3.920100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>4.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>4.070600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>4.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>3.976500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>3.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>4.026300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>3.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>3.810700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>3.908200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>3.733800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.776900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>3.666100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>3.836000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>3.692700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>3.815900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>3.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>3.951700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>3.668700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>3.880200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>4.185400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>3.756600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>3.862900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>4.107300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>3.828700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>4.190200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>3.626800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>3.820600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>3.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>4.079200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>4.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>4.103900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>3.946200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>4.218300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>3.986500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>3.998800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>3.684500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>3.999300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>3.771200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>3.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.460300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>4.120700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>3.920400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>3.971000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>4.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>3.915500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>3.851000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>3.928800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>3.805500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>4.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.872600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>3.757300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>3.984300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>3.813200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>3.947900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>3.992300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>3.556300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>3.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>3.934800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>4.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.706300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>3.634400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>3.852000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>4.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>3.427600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>4.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>3.775700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>3.856600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>4.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>4.175300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.798000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>3.853700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>3.234400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>3.842500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>3.412500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>3.968600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>3.873600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>4.092400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>3.799300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>3.810100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>4.160100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>4.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>4.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>3.855400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>3.969800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>3.891400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>3.581200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>3.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>4.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>3.682600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.939600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>3.785600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>3.835400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>3.905300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>4.238600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>3.964900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>4.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>3.998300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>3.640600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>4.096500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.827100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>3.637700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>3.983700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>4.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>3.582500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>3.639000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>3.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>4.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>4.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>4.186200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.162500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>4.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>3.865400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>3.892400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>4.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>3.828600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>3.895900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>4.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>4.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>3.975000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.738600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>3.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>3.824900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>3.905000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>4.098200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>3.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>3.893100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>3.789300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>3.836400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>3.912400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>4.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>3.967000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>4.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>4.095200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>4.137100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>3.641300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>3.916600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>3.964600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>4.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>4.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.797900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>4.153700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>3.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>3.936800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>4.036100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>3.579000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>4.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>4.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>3.741900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>3.833000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>4.059000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>4.130900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>3.802700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>3.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>3.947500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>3.529400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>3.773000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>4.079800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>3.812200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>3.634000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.582400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>3.705300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>3.853800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>3.981100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>3.799500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>4.099200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>3.931300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>3.904400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>3.817900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>4.207800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.612000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>3.795800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>4.028300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>4.057300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>3.817200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>3.975400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>3.837800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>4.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>3.951600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>3.459800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>4.093400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>4.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>3.717000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>3.997700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>3.986900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>3.945000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>3.671500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>3.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>3.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>4.047900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>3.928800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>3.854500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>3.842600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>4.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>3.924500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>3.732500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>3.976100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>3.879500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>3.895200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>3.969600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>4.012200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>3.825700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>3.908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>3.735100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>4.095700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>3.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>4.043400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>3.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>4.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>3.630500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>3.977500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "2d5750ac-4893-482a-c82d-7815d562931d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1171.1532 seconds used for training.\n",
            "19.52 minutes used for training.\n",
            "Peak reserved memory = 12.057 GB.\n",
            "Peak reserved memory for training = 6.219 GB.\n",
            "Peak reserved memory % of max memory = 81.792 %.\n",
            "Peak reserved memory for training % of max memory = 42.188 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "eece7397-94d1-4e99-e44c-c46dfc39a6d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n[Role]: You are an expert in the field of rare disease. You will be provided and asked about a complicated clinical case; read it carefully and then provide a diverse and comprehensive differential diagnosis disease. Please write down the reasoning process, no more than 5 reasoning steps. Let's think step by step.\\n### Input:\\nPatients phenotype:Abnormal vertebral morphology, Cutaneous syndactyly, Cerebral atrophy, Short stature, Arthralgia, Hypoplasia of the corpus callosum\\n### Response:\\nMultiple epiphyseal dysplasia, Al-Gazali type, is a rare genetic disorder characterized by abnormalities in the skeletal system, brain, and skin. Based on the patient's phenotype, I will outline a differential diagnosis with a reasoning process:\\n\\nStep 1: The patient's abnormal vertebral morphology and short stature suggest a possible diagnosis of skeletal dysplasia. This is a common feature among various types of epiphyseal dysplasias.\\n\\nStep 2: The presence of cutaneous syndactyly (webbed fingers and toes) is a distinctive feature of Al-Gazali syndrome. This feature is not typically seen in other epiphyseal dysplasias, making it a strong indicator of this diagnosis.\\n\\nStep 3: The patient's cerebral atrophy and hypoplasia of the corpus callosum suggest a possible diagnosis of a neurodevelopmental disorder. Al-Gazali syndrome is known to affect the brain, leading to intellectual disability and other neurological symptoms.\\n\\nStep 4: The patient's arthralgia (joint pain) is a common feature among various types of epiphyseal dysplasias, including Al-Gazali syndrome. This symptom is often associated with joint instability and deformity.\\n\\nStep 5: Considering the patient's phenotype and the reasoning process outlined above, I conclude that the most likely diagnosis is Al-Gazali type multiple epiphyseal dysplasia. This diagnosis is supported by the presence of cutaneous syndactyly, abnormal vertebral morphology, and cerebral atrophy, which are all characteristic features of this rare genetic disorder.\\n\\nIn conclusion, the patient's symptoms are consistent with a diagnosis of Al-Gazali type multiple epiphyseal dysplasia. Further genetic testing and imaging studies would be necessary to confirm this diagnosis. The patient would likely require multidisciplinary care from a team of specialists, including orthopedic surgeons, neurologists, and geneticists. Treatment would focus on managing symptoms, preventing complications, and improving quality of life. [End of Response] ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]]> ]\"]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"\"\"[Role]: You are an expert in the field of rare disease. You will be provided and asked about a complicated clinical case; read it carefully and then provide a diverse and comprehensive differential diagnosis disease. Please write down the reasoning process, no more than 5 reasoning steps. Let's think step by step.\"\"\", # instruction\n",
        "        'Patients phenotype:Abnormal vertebral morphology, Cutaneous syndactyly, Cerebral atrophy, Short stature, Arthralgia, Hypoplasia of the corpus callosum', # input\n",
        "        \"Multiple epiphyseal dysplasia, Al-Gazali type\", # ÁúüÂÆûËæìÂá∫\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "030a6e13-9371-4717-c5c5-d4e3563e0cca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(\"outputs\", tokenizer, save_method = \"merged_16bit\",) #ÂêàÂπ∂Ê®°ÂûãÔºå‰øùÂ≠ò‰∏∫16‰Ωçhf"
      ],
      "metadata": {
        "id": "fbwxmgJQAY2T",
        "outputId": "a8268412-0b0a-45bb-a093-b047e443afdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 5.7G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 5.6 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|‚ñà‚ñà‚ñà‚ñä      | 12/32 [00:01<00:01, 13.06it/s]\n",
            "We will save to Disk and not RAM now.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [01:14<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving outputs/pytorch_model-00001-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00002-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00003-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00004-of-00004.bin...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "\n",
        "# ËøôÈáåÈúÄË¶ÅËæìÂÖ•Ôºö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\n",
        "!pip install huggingface-cli\n",
        "!pip install huggingface_hub[hf_transfer]\n",
        "!export HF_HUB_ENABLE_HF_TRANSFER=1\n"
      ],
      "metadata": {
        "id": "19Z-Wz_8_6jL",
        "outputId": "1ad04c40-4a31-4c17-ce48-cd3aedcd5c8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "The token `cl` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `cl`\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-cli (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-cli\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (4.12.2)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]) (0.1.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_transfer]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_transfer]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_transfer]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_transfer]) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli upload llama3-inst-rd_phenotype_disease /content/outputs"
      ],
      "metadata": {
        "id": "bPCSHpW0AGjb",
        "outputId": "63458ae6-aecf-44f5-9b22-74cc0ad88e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start hashing 21 files.\n",
            "Finished hashing 21 files.\n",
            "  0% 0/11 [00:00<?, ?it/s]\n",
            "checkpoint-250/adapter_model.safetensors:   0% 0.00/168M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  10% 16.0M/168M [00:01<00:13, 11.6MB/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  19% 32.0M/168M [00:01<00:05, 23.5MB/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  29% 48.0M/168M [00:01<00:03, 36.3MB/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  38% 64.0M/168M [00:02<00:02, 40.4MB/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  57% 96.0M/168M [00:02<00:00, 72.2MB/s]\u001b[A\n",
            "checkpoint-250/adapter_model.safetensors:  86% 144M/168M [00:02<00:00, 127MB/s]  \u001b[A\n",
            "checkpoint-250/adapter_model.safetensors: 176MB [00:02, 61.3MB/s]\n",
            "  9% 1/11 [00:03<00:32,  3.25s/it]\n",
            "checkpoint-250/optimizer.pt:   0% 0.00/85.7M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-250/optimizer.pt:  19% 16.0M/85.7M [00:00<00:03, 17.9MB/s]\u001b[A\n",
            "checkpoint-250/optimizer.pt:  37% 32.0M/85.7M [00:01<00:01, 34.6MB/s]\u001b[A\n",
            "checkpoint-250/optimizer.pt:  56% 48.0M/85.7M [00:01<00:01, 36.5MB/s]\u001b[A\n",
            "checkpoint-250/optimizer.pt: 96.0MB [00:02, 43.8MB/s]                \n",
            " 18% 2/11 [00:05<00:25,  2.84s/it]\n",
            "checkpoint-250/rng_state.pth:   0% 0.00/14.2k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-250/rng_state.pth: 16.0MB [00:00, 55.2MB/s]\n",
            " 27% 3/11 [00:06<00:14,  1.87s/it]\n",
            "checkpoint-250/scheduler.pt:   0% 0.00/1.06k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-250/scheduler.pt: 16.0MB [00:00, 59.3MB/s]\n",
            " 36% 4/11 [00:07<00:09,  1.37s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:00<00:00, 39.2MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:00, 38.8MB/s]\n",
            " 45% 5/11 [00:08<00:07,  1.30s/it]\n",
            "checkpoint-250/training_args.bin:   0% 0.00/5.56k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-250/training_args.bin: 16.0MB [00:00, 17.7MB/s]\n",
            " 55% 6/11 [00:09<00:06,  1.28s/it]\n",
            "pytorch_model-00001-of-00004.bin:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   0% 16.0M/4.98G [00:09<47:01, 1.76MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 32.0M/4.98G [00:10<22:41, 3.63MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 64.0M/4.98G [00:11<09:52, 8.30MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 80.0M/4.98G [00:11<07:37, 10.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 96.0M/4.98G [00:11<05:28, 14.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 112M/4.98G [00:12<04:42, 17.2MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 128M/4.98G [00:12<03:36, 22.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 160M/4.98G [00:12<02:15, 35.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   4% 176M/4.98G [00:13<02:13, 36.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   4% 208M/4.98G [00:13<01:26, 55.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 240M/4.98G [00:13<01:14, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 256M/4.98G [00:14<01:08, 68.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 272M/4.98G [00:14<01:00, 77.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   6% 304M/4.98G [00:14<00:52, 89.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   7% 336M/4.98G [00:14<00:39, 119MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   7% 368M/4.98G [00:14<00:33, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   8% 416M/4.98G [00:14<00:26, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   9% 448M/4.98G [00:15<00:36, 124MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  10% 496M/4.98G [00:15<00:28, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  11% 528M/4.98G [00:15<00:32, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  11% 560M/4.98G [00:15<00:31, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  12% 592M/4.98G [00:16<00:29, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  13% 624M/4.98G [00:16<00:29, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  13% 656M/4.98G [00:16<00:33, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  14% 688M/4.98G [00:16<00:28, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  15% 736M/4.98G [00:16<00:21, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  15% 768M/4.98G [00:17<00:19, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  16% 816M/4.98G [00:17<00:18, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  17% 864M/4.98G [00:17<00:16, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  18% 896M/4.98G [00:17<00:16, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  19% 944M/4.98G [00:17<00:14, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  20% 992M/4.98G [00:17<00:14, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  21% 1.02G/4.98G [00:18<00:14, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  21% 1.06G/4.98G [00:18<00:13, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  22% 1.09G/4.98G [00:18<00:14, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  23% 1.12G/4.98G [00:18<00:14, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  23% 1.15G/4.98G [00:18<00:16, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  24% 1.18G/4.98G [00:18<00:16, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  24% 1.22G/4.98G [00:18<00:19, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  25% 1.25G/4.98G [00:19<00:17, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  26% 1.28G/4.98G [00:19<00:19, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  27% 1.34G/4.98G [00:19<00:15, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  28% 1.39G/4.98G [00:19<00:15, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  29% 1.42G/4.98G [00:20<00:21, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  30% 1.49G/4.98G [00:20<00:15, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  31% 1.52G/4.98G [00:20<00:16, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  31% 1.55G/4.98G [00:20<00:15, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  32% 1.58G/4.98G [00:21<00:30, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  32% 1.62G/4.98G [00:21<00:25, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  33% 1.66G/4.98G [00:21<00:18, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  34% 1.70G/4.98G [00:21<00:29, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  35% 1.73G/4.98G [00:22<00:24, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  36% 1.78G/4.98G [00:22<00:19, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  36% 1.81G/4.98G [00:22<00:22, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  37% 1.86G/4.98G [00:22<00:18, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  38% 1.90G/4.98G [00:23<00:26, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  39% 1.94G/4.98G [00:24<00:45, 67.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  39% 1.95G/4.98G [00:24<00:43, 68.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 1.97G/4.98G [00:24<00:41, 72.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 1.98G/4.98G [00:25<00:43, 69.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.02G/4.98G [00:25<00:46, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.03G/4.98G [00:25<00:42, 69.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.05G/4.98G [00:26<00:53, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.06G/4.98G [00:26<00:47, 61.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.08G/4.98G [00:26<00:50, 57.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.10G/4.98G [00:27<00:47, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.11G/4.98G [00:27<00:40, 69.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.14G/4.98G [00:27<00:28, 100MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.16G/4.98G [00:27<00:30, 91.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.19G/4.98G [00:27<00:28, 96.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.21G/4.98G [00:28<00:28, 96.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  45% 2.24G/4.98G [00:28<00:24, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.27G/4.98G [00:28<00:27, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.29G/4.98G [00:29<00:33, 80.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.32G/4.98G [00:29<00:24, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.34G/4.98G [00:29<00:25, 103MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.35G/4.98G [00:29<00:28, 92.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  48% 2.37G/4.98G [00:29<00:26, 100MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  48% 2.40G/4.98G [00:29<00:19, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  49% 2.45G/4.98G [00:29<00:12, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  50% 2.48G/4.98G [00:30<00:19, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  50% 2.51G/4.98G [00:30<00:17, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.54G/4.98G [00:30<00:21, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.56G/4.98G [00:31<00:21, 111MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  52% 2.59G/4.98G [00:31<00:20, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  52% 2.61G/4.98G [00:31<00:22, 105MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  53% 2.62G/4.98G [00:31<00:21, 112MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  53% 2.66G/4.98G [00:31<00:16, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.69G/4.98G [00:32<00:23, 96.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.70G/4.98G [00:32<00:21, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  55% 2.74G/4.98G [00:32<00:17, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  56% 2.77G/4.98G [00:32<00:15, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  57% 2.83G/4.98G [00:32<00:09, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  58% 2.88G/4.98G [00:33<00:08, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.91G/4.98G [00:33<00:08, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.96G/4.98G [00:33<00:12, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  60% 2.99G/4.98G [00:34<00:19, 102MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  61% 3.06G/4.98G [00:34<00:13, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  62% 3.09G/4.98G [00:34<00:13, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  63% 3.12G/4.98G [00:35<00:16, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  63% 3.14G/4.98G [00:35<00:21, 86.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.17G/4.98G [00:35<00:17, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.18G/4.98G [00:35<00:16, 108MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.20G/4.98G [00:36<00:17, 102MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  65% 3.22G/4.98G [00:36<00:17, 100MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  66% 3.26G/4.98G [00:36<00:18, 92.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  66% 3.28G/4.98G [00:37<00:17, 96.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  67% 3.34G/4.98G [00:37<00:10, 152MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  68% 3.39G/4.98G [00:37<00:08, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  69% 3.46G/4.98G [00:37<00:06, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  70% 3.49G/4.98G [00:37<00:07, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  71% 3.52G/4.98G [00:38<00:10, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  72% 3.57G/4.98G [00:38<00:07, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  72% 3.60G/4.98G [00:38<00:07, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  73% 3.65G/4.98G [00:38<00:07, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  74% 3.70G/4.98G [00:39<00:07, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  75% 3.73G/4.98G [00:39<00:08, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  76% 3.76G/4.98G [00:39<00:07, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  76% 3.79G/4.98G [00:39<00:06, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  77% 3.86G/4.98G [00:39<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  78% 3.89G/4.98G [00:39<00:04, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  79% 3.94G/4.98G [00:40<00:03, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  80% 3.97G/4.98G [00:40<00:04, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  81% 4.03G/4.98G [00:40<00:03, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  82% 4.10G/4.98G [00:40<00:02, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  83% 4.13G/4.98G [00:40<00:03, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.16G/4.98G [00:40<00:02, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.19G/4.98G [00:41<00:03, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  86% 4.27G/4.98G [00:41<00:02, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  87% 4.34G/4.98G [00:41<00:01, 345MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  88% 4.38G/4.98G [00:41<00:01, 357MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  89% 4.43G/4.98G [00:41<00:01, 317MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  90% 4.48G/4.98G [00:42<00:01, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  91% 4.54G/4.98G [00:42<00:01, 320MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  93% 4.61G/4.98G [00:42<00:00, 376MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  94% 4.69G/4.98G [00:42<00:00, 461MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  96% 4.77G/4.98G [00:42<00:00, 468MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  97% 4.85G/4.98G [00:42<00:00, 542MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  99% 4.91G/4.98G [00:42<00:00, 546MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin: 4.99GB [00:42, 116MB/s]                \n",
            " 64% 7/11 [00:52<01:00, 15.06s/it]\n",
            "pytorch_model-00002-of-00004.bin:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   0% 16.0M/5.00G [00:09<47:08, 1.76MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 32.0M/5.00G [00:09<20:36, 4.02MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 48.0M/5.00G [00:10<12:33, 6.57MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 64.0M/5.00G [00:10<08:30, 9.67MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 80.0M/5.00G [00:11<06:49, 12.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 96.0M/5.00G [00:11<04:55, 16.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   3% 128M/5.00G [00:11<02:39, 30.6MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   3% 144M/5.00G [00:12<03:01, 26.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 176M/5.00G [00:12<02:06, 38.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 208M/5.00G [00:13<01:28, 54.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 240M/5.00G [00:13<01:27, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 256M/5.00G [00:13<01:30, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 272M/5.00G [00:14<01:33, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   6% 288M/5.00G [00:14<01:17, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   6% 304M/5.00G [00:14<01:11, 65.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   7% 336M/5.00G [00:14<00:50, 93.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   7% 368M/5.00G [00:15<00:44, 104MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   8% 384M/5.00G [00:15<00:45, 102MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   9% 432M/5.00G [00:15<00:29, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  10% 480M/5.00G [00:15<00:23, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  10% 512M/5.00G [00:15<00:26, 168MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  12% 592M/5.00G [00:15<00:16, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  13% 640M/5.00G [00:16<00:16, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  14% 688M/5.00G [00:16<00:16, 263MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  14% 720M/5.00G [00:16<00:20, 211MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  16% 800M/5.00G [00:17<00:23, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  17% 848M/5.00G [00:17<00:23, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  18% 880M/5.00G [00:17<00:24, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  18% 912M/5.00G [00:17<00:29, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  19% 944M/5.00G [00:18<00:28, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  20% 976M/5.00G [00:18<00:24, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  20% 1.02G/5.00G [00:18<00:19, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  21% 1.07G/5.00G [00:18<00:20, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  22% 1.10G/5.00G [00:18<00:18, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  23% 1.14G/5.00G [00:19<00:23, 166MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  24% 1.20G/5.00G [00:19<00:17, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  25% 1.25G/5.00G [00:19<00:16, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  26% 1.28G/5.00G [00:19<00:17, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  26% 1.31G/5.00G [00:19<00:18, 202MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  28% 1.41G/5.00G [00:19<00:11, 318MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  29% 1.46G/5.00G [00:20<00:11, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  30% 1.50G/5.00G [00:20<00:12, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  31% 1.54G/5.00G [00:20<00:16, 210MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  31% 1.57G/5.00G [00:20<00:19, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  32% 1.60G/5.00G [00:20<00:17, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  33% 1.66G/5.00G [00:21<00:15, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  34% 1.70G/5.00G [00:21<00:22, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  35% 1.73G/5.00G [00:21<00:19, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  35% 1.76G/5.00G [00:22<00:20, 160MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  36% 1.79G/5.00G [00:22<00:18, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  36% 1.82G/5.00G [00:22<00:23, 136MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  37% 1.86G/5.00G [00:23<00:35, 88.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  38% 1.89G/5.00G [00:23<00:30, 101MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  38% 1.90G/5.00G [00:23<00:31, 97.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.94G/5.00G [00:23<00:29, 105MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.95G/5.00G [00:24<00:31, 96.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 1.98G/5.00G [00:24<00:26, 116MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 2.02G/5.00G [00:24<00:24, 122MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.05G/5.00G [00:24<00:23, 123MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.06G/5.00G [00:24<00:26, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.08G/5.00G [00:25<00:34, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.10G/5.00G [00:25<00:30, 94.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.11G/5.00G [00:25<00:38, 75.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.13G/5.00G [00:26<01:06, 43.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.14G/5.00G [00:26<00:54, 52.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.16G/5.00G [00:27<01:11, 39.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.18G/5.00G [00:27<01:09, 40.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.21G/5.00G [00:27<00:43, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.24G/5.00G [00:28<00:32, 84.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.26G/5.00G [00:28<00:30, 88.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.27G/5.00G [00:28<00:38, 71.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  46% 2.29G/5.00G [00:28<00:36, 75.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  46% 2.32G/5.00G [00:28<00:27, 97.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  47% 2.35G/5.00G [00:29<00:26, 99.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  47% 2.37G/5.00G [00:29<00:29, 89.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.38G/5.00G [00:30<00:53, 48.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.42G/5.00G [00:30<00:36, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  49% 2.43G/5.00G [00:30<00:43, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  50% 2.48G/5.00G [00:30<00:24, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  50% 2.51G/5.00G [00:31<00:22, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  51% 2.56G/5.00G [00:31<00:18, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  52% 2.61G/5.00G [00:31<00:14, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  53% 2.64G/5.00G [00:32<00:17, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.69G/5.00G [00:32<00:13, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.72G/5.00G [00:32<00:17, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  55% 2.77G/5.00G [00:32<00:15, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  56% 2.80G/5.00G [00:33<00:14, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  57% 2.83G/5.00G [00:33<00:22, 95.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  57% 2.86G/5.00G [00:33<00:18, 113MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  58% 2.90G/5.00G [00:34<00:21, 96.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.93G/5.00G [00:34<00:23, 89.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.94G/5.00G [00:34<00:22, 91.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 2.98G/5.00G [00:34<00:17, 117MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 3.01G/5.00G [00:35<00:17, 117MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  61% 3.04G/5.00G [00:35<00:18, 107MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  62% 3.09G/5.00G [00:35<00:13, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  62% 3.12G/5.00G [00:35<00:13, 144MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  63% 3.15G/5.00G [00:36<00:13, 138MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  63% 3.17G/5.00G [00:36<00:18, 101MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  64% 3.20G/5.00G [00:36<00:15, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  66% 3.28G/5.00G [00:36<00:09, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  66% 3.31G/5.00G [00:37<00:10, 154MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  68% 3.38G/5.00G [00:37<00:08, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  69% 3.44G/5.00G [00:37<00:07, 212MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  69% 3.47G/5.00G [00:37<00:07, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  70% 3.52G/5.00G [00:38<00:06, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  72% 3.58G/5.00G [00:38<00:05, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  73% 3.63G/5.00G [00:38<00:04, 290MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  73% 3.66G/5.00G [00:38<00:05, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  74% 3.70G/5.00G [00:38<00:07, 184MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  75% 3.73G/5.00G [00:39<00:07, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  76% 3.79G/5.00G [00:39<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  76% 3.82G/5.00G [00:39<00:05, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  77% 3.86G/5.00G [00:39<00:05, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  79% 3.94G/5.00G [00:39<00:04, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  79% 3.97G/5.00G [00:40<00:04, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  81% 4.03G/5.00G [00:40<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  82% 4.08G/5.00G [00:40<00:03, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  82% 4.11G/5.00G [00:40<00:03, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  84% 4.19G/5.00G [00:40<00:02, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  85% 4.26G/5.00G [00:41<00:03, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  87% 4.37G/5.00G [00:41<00:02, 297MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  88% 4.40G/5.00G [00:41<00:02, 282MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  89% 4.46G/5.00G [00:41<00:01, 328MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  90% 4.51G/5.00G [00:41<00:01, 347MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  92% 4.61G/5.00G [00:42<00:01, 362MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  93% 4.66G/5.00G [00:42<00:00, 346MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  94% 4.72G/5.00G [00:42<00:00, 350MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  96% 4.80G/5.00G [00:42<00:00, 408MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  98% 4.88G/5.00G [00:42<00:00, 488MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin: 5.01GB [00:43, 116MB/s]                \n",
            " 73% 8/11 [01:36<01:12, 24.19s/it]\n",
            "pytorch_model-00003-of-00004.bin:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   0% 16.0M/4.92G [00:07<39:06, 2.09MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 32.0M/4.92G [00:08<19:49, 4.11MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 48.0M/4.92G [00:09<12:09, 6.68MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 64.0M/4.92G [00:11<10:36, 7.62MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   2% 80.0M/4.92G [00:11<07:24, 10.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   2% 96.0M/4.92G [00:11<05:03, 15.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 128M/4.92G [00:11<02:54, 27.4MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 144M/4.92G [00:12<02:25, 32.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 160M/4.92G [00:12<02:15, 35.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   4% 208M/4.92G [00:12<01:10, 67.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   5% 224M/4.92G [00:12<01:08, 68.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   5% 240M/4.92G [00:13<01:14, 63.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   6% 272M/4.92G [00:13<01:18, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   6% 288M/4.92G [00:14<01:26, 53.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   6% 304M/4.92G [00:14<01:16, 60.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 320M/4.92G [00:14<01:24, 54.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 352M/4.92G [00:14<00:56, 80.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   8% 384M/4.92G [00:15<00:44, 102MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   8% 416M/4.92G [00:15<00:44, 101MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   9% 448M/4.92G [00:15<00:36, 123MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  10% 480M/4.92G [00:15<00:31, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  11% 528M/4.92G [00:15<00:23, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  11% 560M/4.92G [00:15<00:22, 190MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  12% 592M/4.92G [00:16<00:23, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  13% 624M/4.92G [00:16<00:24, 175MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  13% 656M/4.92G [00:16<00:22, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  14% 688M/4.92G [00:16<00:23, 177MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  15% 736M/4.92G [00:16<00:17, 233MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  16% 768M/4.92G [00:16<00:17, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  16% 800M/4.92G [00:17<00:17, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  17% 832M/4.92G [00:17<00:18, 219MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  18% 864M/4.92G [00:17<00:22, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  18% 896M/4.92G [00:17<00:24, 165MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  19% 928M/4.92G [00:18<00:30, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  19% 944M/4.92G [00:18<00:29, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  20% 992M/4.92G [00:18<00:20, 188MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  21% 1.02G/4.92G [00:18<00:19, 201MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  22% 1.10G/4.92G [00:18<00:13, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  23% 1.15G/4.92G [00:18<00:15, 243MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  24% 1.18G/4.92G [00:19<00:15, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  25% 1.22G/4.92G [00:19<00:16, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  25% 1.25G/4.92G [00:19<00:18, 196MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  26% 1.28G/4.92G [00:19<00:17, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  27% 1.33G/4.92G [00:19<00:15, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  28% 1.39G/4.92G [00:19<00:11, 295MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  29% 1.42G/4.92G [00:20<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  30% 1.47G/4.92G [00:20<00:13, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  31% 1.52G/4.92G [00:20<00:11, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  32% 1.55G/4.92G [00:20<00:14, 232MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  32% 1.58G/4.92G [00:20<00:14, 226MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  33% 1.62G/4.92G [00:20<00:16, 200MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  34% 1.65G/4.92G [00:21<00:24, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  34% 1.68G/4.92G [00:21<00:26, 123MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  35% 1.70G/4.92G [00:21<00:28, 112MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  35% 1.73G/4.92G [00:22<00:24, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  35% 1.74G/4.92G [00:22<00:25, 122MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  36% 1.76G/4.92G [00:22<00:26, 118MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  37% 1.81G/4.92G [00:22<00:20, 150MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  38% 1.86G/4.92G [00:22<00:16, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  38% 1.89G/4.92G [00:22<00:17, 173MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  39% 1.92G/4.92G [00:23<00:15, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  40% 1.95G/4.92G [00:23<00:14, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  40% 1.98G/4.92G [00:23<00:15, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.02G/4.92G [00:23<00:25, 116MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.03G/4.92G [00:24<00:26, 111MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.05G/4.92G [00:24<00:32, 89.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.06G/4.92G [00:24<00:31, 91.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  42% 2.08G/4.92G [00:25<00:45, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  43% 2.11G/4.92G [00:25<00:40, 69.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.14G/4.92G [00:25<00:30, 91.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.16G/4.92G [00:25<00:32, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  45% 2.19G/4.92G [00:26<00:23, 114MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  45% 2.21G/4.92G [00:26<00:24, 111MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.24G/4.92G [00:26<00:36, 73.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.26G/4.92G [00:27<00:33, 79.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.27G/4.92G [00:27<00:46, 57.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.29G/4.92G [00:28<00:52, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.30G/4.92G [00:28<00:44, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.32G/4.92G [00:28<00:43, 60.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.34G/4.92G [00:28<00:39, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.35G/4.92G [00:28<00:42, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.38G/4.92G [00:29<00:32, 78.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.40G/4.92G [00:29<00:35, 70.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.42G/4.92G [00:29<00:36, 69.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.43G/4.92G [00:30<00:50, 49.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.46G/4.92G [00:30<00:43, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.48G/4.92G [00:30<00:38, 62.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  52% 2.54G/4.92G [00:31<00:18, 129MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  52% 2.58G/4.92G [00:31<00:15, 154MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  53% 2.61G/4.92G [00:31<00:15, 144MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  54% 2.64G/4.92G [00:32<00:25, 89.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  54% 2.67G/4.92G [00:32<00:21, 104MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  55% 2.70G/4.92G [00:32<00:19, 115MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  56% 2.74G/4.92G [00:32<00:18, 115MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  56% 2.77G/4.92G [00:32<00:15, 138MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  57% 2.80G/4.92G [00:33<00:15, 140MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  58% 2.83G/4.92G [00:33<00:22, 92.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  58% 2.85G/4.92G [00:34<00:27, 75.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  59% 2.90G/4.92G [00:34<00:19, 104MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  60% 2.96G/4.92G [00:34<00:13, 145MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  61% 2.99G/4.92G [00:34<00:12, 160MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.02G/4.92G [00:35<00:15, 123MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.06G/4.92G [00:35<00:16, 116MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.07G/4.92G [00:35<00:17, 106MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  63% 3.10G/4.92G [00:35<00:15, 117MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  63% 3.12G/4.92G [00:35<00:14, 122MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  64% 3.17G/4.92G [00:36<00:10, 170MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  65% 3.20G/4.92G [00:36<00:09, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  66% 3.23G/4.92G [00:36<00:09, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  66% 3.26G/4.92G [00:36<00:08, 197MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  67% 3.30G/4.92G [00:36<00:07, 209MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  68% 3.34G/4.92G [00:37<00:09, 173MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  69% 3.38G/4.92G [00:37<00:10, 152MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  69% 3.41G/4.92G [00:37<00:11, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  70% 3.46G/4.92G [00:37<00:08, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  71% 3.49G/4.92G [00:37<00:08, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  72% 3.55G/4.92G [00:38<00:05, 230MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  73% 3.60G/4.92G [00:38<00:04, 272MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  74% 3.65G/4.92G [00:38<00:04, 277MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  75% 3.68G/4.92G [00:38<00:05, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  76% 3.71G/4.92G [00:38<00:06, 191MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  76% 3.76G/4.92G [00:39<00:04, 234MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  77% 3.81G/4.92G [00:39<00:04, 265MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  78% 3.84G/4.92G [00:39<00:06, 166MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  79% 3.87G/4.92G [00:39<00:06, 165MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  79% 3.90G/4.92G [00:39<00:05, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  81% 3.98G/4.92G [00:40<00:03, 286MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  82% 4.03G/4.92G [00:40<00:02, 316MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  83% 4.08G/4.92G [00:40<00:02, 297MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  84% 4.13G/4.92G [00:40<00:03, 258MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  85% 4.19G/4.92G [00:40<00:02, 305MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  87% 4.27G/4.92G [00:40<00:01, 384MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  88% 4.32G/4.92G [00:40<00:01, 388MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  89% 4.37G/4.92G [00:41<00:01, 376MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  90% 4.42G/4.92G [00:41<00:01, 349MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  91% 4.46G/4.92G [00:41<00:01, 356MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  92% 4.51G/4.92G [00:41<00:01, 372MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  93% 4.56G/4.92G [00:41<00:00, 377MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  94% 4.61G/4.92G [00:41<00:00, 392MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  96% 4.74G/4.92G [00:41<00:00, 617MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  98% 4.82G/4.92G [00:41<00:00, 590MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin: 4.93GB [00:42, 116MB/s]                \n",
            " 82% 9/11 [02:19<01:00, 30.02s/it]\n",
            "pytorch_model-00004-of-00004.bin:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   1% 16.0M/1.17G [00:00<01:07, 17.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   3% 32.0M/1.17G [00:03<02:21, 8.03MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   4% 48.0M/1.17G [00:05<02:05, 8.93MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   5% 64.0M/1.17G [00:05<01:20, 13.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   7% 80.0M/1.17G [00:05<00:56, 19.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   8% 96.0M/1.17G [00:06<00:53, 20.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  10% 112M/1.17G [00:06<00:47, 22.3MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  11% 128M/1.17G [00:07<00:38, 26.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  16% 192M/1.17G [00:07<00:17, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  21% 240M/1.17G [00:07<00:11, 80.9MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  22% 256M/1.17G [00:08<00:10, 85.0MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  25% 288M/1.17G [00:08<00:08, 107MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  27% 320M/1.17G [00:08<00:07, 108MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  33% 384M/1.17G [00:08<00:05, 150MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  36% 416M/1.17G [00:08<00:04, 163MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  42% 496M/1.17G [00:09<00:02, 244MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  52% 608M/1.17G [00:09<00:01, 361MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  56% 656M/1.17G [00:09<00:01, 312MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  63% 736M/1.17G [00:09<00:01, 394MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  68% 800M/1.17G [00:09<00:01, 330MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  73% 848M/1.17G [00:09<00:00, 330MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  78% 912M/1.17G [00:10<00:00, 374MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  84% 976M/1.17G [00:10<00:00, 420MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin: 1.18GB [00:10, 114MB/s]                \n",
            " 91% 10/11 [02:30<00:24, 24.07s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:00<00:00, 34.8MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:00, 33.3MB/s]\n",
            "100% 11/11 [02:31<00:00, 13.78s/it]\n",
            "https://huggingface.co/gcc009/llama3-inst-rd_phenotype_disease/tree/main/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q54p_UbpAGqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "f8e7d3fe-8e4d-49ee-944f-08e70cdc1d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is a famous tall tower in Paris?\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "One of the most famous and iconic tall towers in Paris is the Eiffel Tower. Standing at 324 meters (1,063 feet) tall, this wrought iron tower is a symbol of the city and a must-see attraction for tourists from all over the world.<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"What is a famous tall tower in Paris?\", # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")"
      ],
      "metadata": {
        "id": "XhvUOFqBDudk",
        "outputId": "13b983a1-ff7d-494b-f06f-069df3bab5bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 6.24 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [01:39<00:00,  3.10s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model/pytorch_model-00001-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00002-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00003-of-00004.bin...\n",
            "Unsloth: Saving model/pytorch_model-00004-of-00004.bin...\n",
            "Done.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['f16'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at model into f16 GGUF format.\n",
            "The output location will be /content/model/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: model\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 8192\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "2025-02-11 08:16:17.249572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739261777.275613   18031 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739261777.285506   18031 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128255\n",
            "INFO:gguf.vocab:Setting chat_template to {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/model/unsloth.F16.gguf: n_tensors = 291, total_size = 16.1G\n",
            "Writing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16.1G/16.1G [03:25<00:00, 78.1Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/model/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/model/unsloth.F16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli upload llama3-inst-rd_phenotype_disease-GGUF /content/model"
      ],
      "metadata": {
        "id": "xzMijYZTELy8",
        "outputId": "16746545-3b3d-4988-c61b-5dfdb1311a57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start hashing 11 files.\n",
            "Finished hashing 11 files.\n",
            "  0% 0/6 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00004.bin:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   0% 16.0M/4.98G [00:09<47:06, 1.75MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 32.0M/4.98G [00:10<23:22, 3.53MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 48.0M/4.98G [00:10<13:16, 6.19MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   1% 64.0M/4.98G [00:12<11:14, 7.29MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 80.0M/4.98G [00:12<08:10, 9.97MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   2% 96.0M/4.98G [00:13<05:36, 14.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 128M/4.98G [00:13<03:00, 26.8MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 144M/4.98G [00:13<02:31, 32.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   3% 160M/4.98G [00:13<02:02, 39.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   4% 176M/4.98G [00:13<01:43, 46.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 224M/4.98G [00:13<00:55, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 240M/4.98G [00:14<00:54, 86.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 256M/4.98G [00:14<00:49, 94.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   5% 272M/4.98G [00:14<00:57, 81.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   6% 304M/4.98G [00:14<00:41, 112MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   7% 368M/4.98G [00:15<00:39, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   8% 400M/4.98G [00:15<00:34, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:   9% 448M/4.98G [00:15<00:26, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  10% 480M/4.98G [00:15<00:25, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  10% 512M/4.98G [00:15<00:24, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  11% 544M/4.98G [00:16<00:28, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  12% 576M/4.98G [00:16<00:26, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  12% 608M/4.98G [00:16<00:29, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  13% 656M/4.98G [00:16<00:22, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  14% 688M/4.98G [00:16<00:21, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  14% 720M/4.98G [00:16<00:23, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  15% 752M/4.98G [00:17<00:20, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  16% 784M/4.98G [00:17<00:19, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  16% 816M/4.98G [00:17<00:25, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  17% 848M/4.98G [00:17<00:22, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  19% 928M/4.98G [00:17<00:14, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  20% 976M/4.98G [00:17<00:13, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  21% 1.02G/4.98G [00:18<00:13, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  21% 1.06G/4.98G [00:18<00:13, 293MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  22% 1.10G/4.98G [00:18<00:13, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  23% 1.14G/4.98G [00:18<00:19, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  24% 1.18G/4.98G [00:18<00:20, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  25% 1.23G/4.98G [00:19<00:18, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  26% 1.30G/4.98G [00:19<00:15, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  27% 1.33G/4.98G [00:19<00:15, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  28% 1.38G/4.98G [00:19<00:12, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  29% 1.42G/4.98G [00:19<00:12, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  30% 1.47G/4.98G [00:19<00:12, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  30% 1.50G/4.98G [00:20<00:13, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  31% 1.54G/4.98G [00:20<00:15, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  32% 1.57G/4.98G [00:20<00:14, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  33% 1.65G/4.98G [00:20<00:09, 333MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  34% 1.71G/4.98G [00:20<00:09, 346MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  35% 1.76G/4.98G [00:21<00:14, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  36% 1.79G/4.98G [00:21<00:14, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  37% 1.82G/4.98G [00:21<00:21, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  38% 1.87G/4.98G [00:22<00:21, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  38% 1.90G/4.98G [00:22<00:23, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  39% 1.94G/4.98G [00:22<00:28, 106MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  39% 1.95G/4.98G [00:23<00:36, 82.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 1.97G/4.98G [00:23<00:37, 80.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 1.98G/4.98G [00:23<00:36, 81.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  40% 2.00G/4.98G [00:24<00:41, 71.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.02G/4.98G [00:24<00:44, 66.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.03G/4.98G [00:24<00:47, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  41% 2.06G/4.98G [00:24<00:34, 85.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.08G/4.98G [00:25<00:47, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.10G/4.98G [00:25<01:04, 44.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  42% 2.11G/4.98G [00:26<01:03, 45.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.13G/4.98G [00:27<01:37, 29.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.14G/4.98G [00:27<01:22, 34.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  43% 2.16G/4.98G [00:27<01:12, 38.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.19G/4.98G [00:28<00:49, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  44% 2.21G/4.98G [00:28<00:52, 52.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  45% 2.22G/4.98G [00:28<00:46, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.27G/4.98G [00:29<00:37, 71.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  46% 2.30G/4.98G [00:29<00:34, 76.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.34G/4.98G [00:29<00:29, 88.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  47% 2.35G/4.98G [00:30<00:35, 74.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  48% 2.40G/4.98G [00:30<00:23, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  49% 2.42G/4.98G [00:30<00:26, 98.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  49% 2.43G/4.98G [00:30<00:24, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  50% 2.48G/4.98G [00:30<00:18, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.53G/4.98G [00:31<00:15, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  51% 2.56G/4.98G [00:31<00:18, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  52% 2.58G/4.98G [00:32<00:28, 83.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  52% 2.61G/4.98G [00:32<00:24, 96.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  53% 2.64G/4.98G [00:32<00:26, 89.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.67G/4.98G [00:33<00:24, 94.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.69G/4.98G [00:33<00:23, 96.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  54% 2.70G/4.98G [00:33<00:22, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  55% 2.72G/4.98G [00:33<00:23, 96.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  56% 2.77G/4.98G [00:33<00:18, 122MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  57% 2.83G/4.98G [00:34<00:12, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  58% 2.90G/4.98G [00:34<00:09, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.93G/4.98G [00:34<00:10, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  59% 2.96G/4.98G [00:34<00:10, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  60% 3.01G/4.98G [00:34<00:08, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  61% 3.04G/4.98G [00:35<00:11, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  62% 3.07G/4.98G [00:35<00:13, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  62% 3.10G/4.98G [00:35<00:13, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  63% 3.12G/4.98G [00:35<00:13, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.17G/4.98G [00:35<00:09, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  64% 3.20G/4.98G [00:36<00:10, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  65% 3.23G/4.98G [00:36<00:10, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  66% 3.30G/4.98G [00:36<00:07, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  67% 3.33G/4.98G [00:36<00:09, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  68% 3.36G/4.98G [00:36<00:08, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  68% 3.39G/4.98G [00:37<00:07, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  69% 3.42G/4.98G [00:37<00:06, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  69% 3.46G/4.98G [00:37<00:07, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  70% 3.49G/4.98G [00:37<00:07, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  71% 3.52G/4.98G [00:37<00:07, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  71% 3.55G/4.98G [00:37<00:07, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  73% 3.62G/4.98G [00:37<00:05, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  74% 3.68G/4.98G [00:38<00:03, 345MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  75% 3.73G/4.98G [00:38<00:04, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  76% 3.76G/4.98G [00:38<00:04, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  77% 3.81G/4.98G [00:38<00:04, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  77% 3.86G/4.98G [00:38<00:04, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  78% 3.89G/4.98G [00:39<00:06, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  79% 3.92G/4.98G [00:39<00:06, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  80% 3.98G/4.98G [00:39<00:04, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  81% 4.02G/4.98G [00:39<00:04, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  81% 4.05G/4.98G [00:39<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  82% 4.10G/4.98G [00:40<00:03, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  83% 4.13G/4.98G [00:40<00:03, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.16G/4.98G [00:40<00:03, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  84% 4.19G/4.98G [00:40<00:04, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  85% 4.22G/4.98G [00:40<00:03, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  86% 4.27G/4.98G [00:40<00:02, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  86% 4.30G/4.98G [00:41<00:03, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  87% 4.35G/4.98G [00:41<00:03, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  89% 4.42G/4.98G [00:41<00:02, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  90% 4.46G/4.98G [00:41<00:02, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  90% 4.50G/4.98G [00:42<00:02, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  91% 4.53G/4.98G [00:42<00:02, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  92% 4.58G/4.98G [00:42<00:01, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  93% 4.64G/4.98G [00:42<00:01, 327MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  94% 4.69G/4.98G [00:42<00:00, 331MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  95% 4.74G/4.98G [00:42<00:00, 341MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin:  97% 4.82G/4.98G [00:42<00:00, 446MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00004.bin: 4.99GB [00:44, 112MB/s]                \n",
            " 17% 1/6 [00:45<03:45, 45.03s/it]\n",
            "pytorch_model-00002-of-00004.bin:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   0% 16.0M/5.00G [00:10<52:13, 1.59MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 32.0M/5.00G [00:11<24:32, 3.37MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 48.0M/5.00G [00:11<14:23, 5.74MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   1% 64.0M/5.00G [00:12<10:04, 8.17MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 80.0M/5.00G [00:12<07:31, 10.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 96.0M/5.00G [00:12<05:07, 15.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   2% 112M/5.00G [00:13<03:45, 21.6MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   3% 128M/5.00G [00:13<03:07, 26.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   3% 160M/5.00G [00:13<01:48, 44.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 192M/5.00G [00:13<01:10, 68.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   4% 224M/5.00G [00:13<00:55, 85.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 256M/5.00G [00:14<00:48, 96.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   5% 272M/5.00G [00:14<00:56, 84.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   6% 320M/5.00G [00:14<00:37, 125MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   7% 368M/5.00G [00:14<00:31, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   8% 400M/5.00G [00:15<00:29, 156MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   9% 432M/5.00G [00:15<00:30, 151MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:   9% 464M/5.00G [00:15<00:36, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  11% 544M/5.00G [00:15<00:20, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  12% 592M/5.00G [00:15<00:19, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  12% 624M/5.00G [00:16<00:19, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  13% 656M/5.00G [00:16<00:19, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  14% 688M/5.00G [00:16<00:18, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  14% 720M/5.00G [00:16<00:19, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  15% 752M/5.00G [00:16<00:18, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  16% 784M/5.00G [00:16<00:20, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  17% 848M/5.00G [00:16<00:14, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  18% 880M/5.00G [00:17<00:19, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  18% 912M/5.00G [00:17<00:24, 168MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  19% 960M/5.00G [00:17<00:18, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  20% 992M/5.00G [00:17<00:18, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  20% 1.02G/5.00G [00:17<00:19, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  21% 1.06G/5.00G [00:18<00:20, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  22% 1.09G/5.00G [00:18<00:18, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  23% 1.14G/5.00G [00:18<00:14, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  25% 1.25G/5.00G [00:18<00:11, 333MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  26% 1.30G/5.00G [00:18<00:14, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  27% 1.33G/5.00G [00:19<00:17, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  27% 1.36G/5.00G [00:19<00:23, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  28% 1.39G/5.00G [00:19<00:21, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  28% 1.42G/5.00G [00:19<00:20, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  29% 1.46G/5.00G [00:20<00:19, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  30% 1.49G/5.00G [00:20<00:20, 168MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  30% 1.52G/5.00G [00:20<00:19, 182MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  31% 1.55G/5.00G [00:20<00:18, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  32% 1.58G/5.00G [00:20<00:18, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  32% 1.62G/5.00G [00:21<00:19, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  33% 1.65G/5.00G [00:21<00:29, 115MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  33% 1.66G/5.00G [00:21<00:29, 114MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  34% 1.70G/5.00G [00:21<00:25, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  35% 1.73G/5.00G [00:21<00:20, 160MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  36% 1.78G/5.00G [00:22<00:16, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  36% 1.81G/5.00G [00:22<00:18, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  37% 1.84G/5.00G [00:22<00:16, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  37% 1.87G/5.00G [00:22<00:21, 148MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  38% 1.90G/5.00G [00:22<00:17, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.94G/5.00G [00:23<00:18, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  39% 1.97G/5.00G [00:23<00:28, 105MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 1.98G/5.00G [00:23<00:32, 93.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 2.00G/5.00G [00:24<00:32, 92.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  40% 2.02G/5.00G [00:24<00:32, 92.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.05G/5.00G [00:24<00:31, 94.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  41% 2.06G/5.00G [00:25<01:01, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.08G/5.00G [00:25<00:55, 53.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.10G/5.00G [00:26<01:02, 46.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  42% 2.11G/5.00G [00:26<00:51, 55.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.13G/5.00G [00:26<00:53, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  43% 2.16G/5.00G [00:27<00:42, 66.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.19G/5.00G [00:27<00:42, 66.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  44% 2.22G/5.00G [00:27<00:31, 87.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.24G/5.00G [00:27<00:36, 76.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.26G/5.00G [00:29<01:08, 40.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  45% 2.27G/5.00G [00:29<01:01, 44.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  46% 2.29G/5.00G [00:29<00:51, 52.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  47% 2.34G/5.00G [00:29<00:35, 75.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.38G/5.00G [00:29<00:22, 116MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  48% 2.42G/5.00G [00:30<00:19, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  49% 2.45G/5.00G [00:30<00:22, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  49% 2.46G/5.00G [00:30<00:21, 117MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  50% 2.50G/5.00G [00:30<00:18, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  51% 2.53G/5.00G [00:30<00:15, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  51% 2.56G/5.00G [00:30<00:13, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  52% 2.59G/5.00G [00:31<00:12, 196MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  52% 2.62G/5.00G [00:31<00:14, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  53% 2.66G/5.00G [00:31<00:16, 140MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.69G/5.00G [00:32<00:22, 101MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  54% 2.70G/5.00G [00:32<00:21, 105MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  55% 2.75G/5.00G [00:32<00:15, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  56% 2.78G/5.00G [00:33<00:31, 71.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  56% 2.82G/5.00G [00:33<00:25, 86.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  57% 2.85G/5.00G [00:33<00:19, 108MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  58% 2.88G/5.00G [00:34<00:22, 94.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  58% 2.91G/5.00G [00:34<00:25, 80.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.93G/5.00G [00:34<00:25, 82.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.94G/5.00G [00:35<00:22, 89.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  59% 2.96G/5.00G [00:35<00:21, 93.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 2.98G/5.00G [00:35<00:20, 99.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  60% 3.01G/5.00G [00:35<00:15, 129MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  61% 3.07G/5.00G [00:35<00:08, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  63% 3.14G/5.00G [00:35<00:08, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  63% 3.17G/5.00G [00:36<00:09, 203MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  64% 3.22G/5.00G [00:36<00:08, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  65% 3.25G/5.00G [00:36<00:09, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  66% 3.30G/5.00G [00:36<00:07, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  67% 3.33G/5.00G [00:36<00:09, 181MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  67% 3.36G/5.00G [00:37<00:11, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  68% 3.39G/5.00G [00:37<00:12, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  68% 3.41G/5.00G [00:37<00:14, 110MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  68% 3.42G/5.00G [00:38<00:14, 112MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  69% 3.46G/5.00G [00:38<00:13, 110MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  70% 3.50G/5.00G [00:38<00:09, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  71% 3.54G/5.00G [00:38<00:11, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  71% 3.55G/5.00G [00:38<00:11, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  73% 3.63G/5.00G [00:39<00:06, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  74% 3.70G/5.00G [00:39<00:04, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  75% 3.74G/5.00G [00:39<00:04, 288MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  76% 3.79G/5.00G [00:39<00:04, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  77% 3.84G/5.00G [00:39<00:03, 291MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  78% 3.89G/5.00G [00:39<00:03, 317MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  79% 3.94G/5.00G [00:40<00:03, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  80% 3.98G/5.00G [00:40<00:03, 302MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  81% 4.03G/5.00G [00:40<00:03, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  81% 4.06G/5.00G [00:40<00:03, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  83% 4.13G/5.00G [00:40<00:02, 334MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  84% 4.18G/5.00G [00:40<00:02, 314MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  84% 4.22G/5.00G [00:41<00:03, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  85% 4.26G/5.00G [00:41<00:03, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  86% 4.29G/5.00G [00:41<00:03, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  88% 4.38G/5.00G [00:41<00:01, 349MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  89% 4.45G/5.00G [00:41<00:01, 339MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  90% 4.50G/5.00G [00:42<00:01, 307MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  91% 4.54G/5.00G [00:42<00:01, 300MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  92% 4.59G/5.00G [00:42<00:01, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  93% 4.64G/5.00G [00:42<00:01, 273MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  95% 4.75G/5.00G [00:42<00:00, 389MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin:  97% 4.86G/5.00G [00:42<00:00, 485MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00004.bin: 5.01GB [00:43, 116MB/s]                \n",
            " 33% 2/6 [01:28<02:56, 44.17s/it]\n",
            "pytorch_model-00003-of-00004.bin:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   0% 16.0M/4.92G [00:09<45:56, 1.78MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 32.0M/4.92G [00:09<19:40, 4.14MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 48.0M/4.92G [00:11<15:31, 5.23MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   1% 64.0M/4.92G [00:11<10:10, 7.95MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   2% 96.0M/4.92G [00:12<05:16, 15.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   2% 112M/4.92G [00:13<05:09, 15.5MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   3% 128M/4.92G [00:13<04:22, 18.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   4% 176M/4.92G [00:13<02:08, 37.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   4% 208M/4.92G [00:14<01:32, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   6% 272M/4.92G [00:14<00:51, 90.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   6% 304M/4.92G [00:14<00:43, 107MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 336M/4.92G [00:14<00:37, 122MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   7% 368M/4.92G [00:14<00:31, 143MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   8% 400M/4.92G [00:14<00:31, 142MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:   9% 432M/4.92G [00:15<00:33, 134MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  10% 480M/4.92G [00:15<00:26, 169MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  11% 528M/4.92G [00:15<00:20, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  11% 560M/4.92G [00:15<00:22, 192MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  12% 608M/4.92G [00:15<00:20, 211MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  13% 640M/4.92G [00:16<00:30, 140MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  14% 672M/4.92G [00:16<00:31, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  14% 704M/4.92G [00:16<00:26, 158MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  15% 752M/4.92G [00:16<00:21, 190MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  16% 784M/4.92G [00:16<00:19, 209MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  17% 848M/4.92G [00:17<00:14, 281MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  18% 896M/4.92G [00:17<00:26, 150MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  20% 976M/4.92G [00:17<00:17, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  21% 1.02G/4.92G [00:18<00:19, 199MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  22% 1.07G/4.92G [00:18<00:20, 185MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  22% 1.10G/4.92G [00:18<00:20, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  24% 1.17G/4.92G [00:18<00:15, 239MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  24% 1.20G/4.92G [00:19<00:19, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  25% 1.23G/4.92G [00:19<00:19, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  27% 1.31G/4.92G [00:19<00:12, 284MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  28% 1.36G/4.92G [00:19<00:16, 220MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  29% 1.41G/4.92G [00:19<00:14, 250MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  30% 1.46G/4.92G [00:20<00:16, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  30% 1.49G/4.92G [00:20<00:15, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  31% 1.52G/4.92G [00:20<00:16, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  32% 1.57G/4.92G [00:20<00:14, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  33% 1.60G/4.92G [00:20<00:15, 214MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  33% 1.63G/4.92G [00:20<00:15, 217MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  34% 1.68G/4.92G [00:21<00:13, 248MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  35% 1.71G/4.92G [00:21<00:19, 166MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  36% 1.76G/4.92G [00:21<00:19, 160MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  36% 1.79G/4.92G [00:22<00:36, 85.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  37% 1.82G/4.92G [00:22<00:31, 98.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  37% 1.84G/4.92G [00:23<00:35, 87.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  38% 1.87G/4.92G [00:23<00:32, 92.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  39% 1.90G/4.92G [00:23<00:27, 111MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  39% 1.92G/4.92G [00:23<00:31, 95.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  40% 1.97G/4.92G [00:24<00:23, 128MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  40% 1.98G/4.92G [00:24<00:22, 130MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.00G/4.92G [00:24<00:22, 129MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.02G/4.92G [00:25<00:49, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  41% 2.03G/4.92G [00:25<00:44, 64.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  43% 2.10G/4.92G [00:25<00:23, 120MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  43% 2.13G/4.92G [00:25<00:24, 114MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.14G/4.92G [00:25<00:26, 103MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.16G/4.92G [00:26<00:28, 98.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  44% 2.18G/4.92G [00:26<00:31, 86.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  45% 2.19G/4.92G [00:26<00:41, 65.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  45% 2.21G/4.92G [00:27<00:38, 70.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.24G/4.92G [00:27<00:36, 74.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  46% 2.26G/4.92G [00:28<00:58, 45.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.30G/4.92G [00:29<01:11, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  47% 2.32G/4.92G [00:30<01:06, 39.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.35G/4.92G [00:30<00:45, 55.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.37G/4.92G [00:30<00:40, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  48% 2.38G/4.92G [00:30<00:39, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.42G/4.92G [00:31<00:39, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  49% 2.43G/4.92G [00:31<00:34, 72.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.45G/4.92G [00:31<00:32, 75.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  50% 2.46G/4.92G [00:31<00:41, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  51% 2.53G/4.92G [00:32<00:21, 111MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  52% 2.56G/4.92G [00:32<00:19, 120MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  53% 2.59G/4.92G [00:32<00:17, 130MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  54% 2.66G/4.92G [00:32<00:11, 201MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  55% 2.69G/4.92G [00:32<00:12, 177MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  55% 2.72G/4.92G [00:33<00:12, 182MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  56% 2.75G/4.92G [00:33<00:15, 137MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  57% 2.80G/4.92G [00:33<00:12, 167MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  58% 2.83G/4.92G [00:33<00:11, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  58% 2.86G/4.92G [00:33<00:10, 194MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  59% 2.90G/4.92G [00:34<00:16, 124MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  60% 2.93G/4.92G [00:34<00:15, 127MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  60% 2.96G/4.92G [00:34<00:14, 136MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  61% 2.99G/4.92G [00:35<00:15, 125MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.02G/4.92G [00:35<00:14, 133MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  62% 3.06G/4.92G [00:35<00:14, 130MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  63% 3.09G/4.92G [00:35<00:13, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  63% 3.10G/4.92G [00:35<00:13, 130MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  64% 3.15G/4.92G [00:36<00:10, 174MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  66% 3.26G/4.92G [00:36<00:04, 343MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  67% 3.31G/4.92G [00:36<00:08, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  68% 3.36G/4.92G [00:37<00:08, 180MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  69% 3.41G/4.92G [00:37<00:08, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  70% 3.46G/4.92G [00:37<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  72% 3.52G/4.92G [00:37<00:05, 271MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  73% 3.57G/4.92G [00:37<00:04, 306MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  74% 3.62G/4.92G [00:37<00:05, 235MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  74% 3.65G/4.92G [00:38<00:07, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  75% 3.68G/4.92G [00:38<00:07, 157MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  76% 3.71G/4.92G [00:38<00:08, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  76% 3.76G/4.92G [00:39<00:07, 164MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  77% 3.81G/4.92G [00:39<00:05, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  79% 3.87G/4.92G [00:39<00:04, 240MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  80% 3.92G/4.92G [00:39<00:03, 272MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  81% 3.97G/4.92G [00:39<00:03, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  81% 4.00G/4.92G [00:39<00:04, 210MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  82% 4.03G/4.92G [00:40<00:04, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  83% 4.06G/4.92G [00:40<00:04, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  83% 4.10G/4.92G [00:40<00:03, 216MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  84% 4.13G/4.92G [00:40<00:04, 183MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  85% 4.16G/4.92G [00:40<00:04, 173MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  85% 4.19G/4.92G [00:41<00:03, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  87% 4.27G/4.92G [00:41<00:02, 259MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  89% 4.37G/4.92G [00:41<00:01, 362MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  90% 4.42G/4.92G [00:41<00:01, 365MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  91% 4.48G/4.92G [00:41<00:01, 399MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  92% 4.53G/4.92G [00:41<00:01, 357MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  93% 4.58G/4.92G [00:41<00:00, 362MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  94% 4.62G/4.92G [00:42<00:00, 366MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  95% 4.67G/4.92G [00:42<00:00, 369MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin:  98% 4.80G/4.92G [00:42<00:00, 514MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00004.bin: 4.93GB [00:42, 116MB/s]                \n",
            " 50% 3/6 [02:11<02:10, 43.61s/it]\n",
            "pytorch_model-00004-of-00004.bin:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   1% 16.0M/1.17G [00:00<00:36, 31.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   3% 32.0M/1.17G [00:04<02:45, 6.87MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   4% 48.0M/1.17G [00:05<02:14, 8.31MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   5% 64.0M/1.17G [00:06<01:35, 11.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:   7% 80.0M/1.17G [00:06<01:06, 16.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  10% 112M/1.17G [00:06<00:36, 29.0MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  11% 128M/1.17G [00:07<00:34, 30.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  12% 144M/1.17G [00:07<00:30, 33.3MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  15% 176M/1.17G [00:07<00:20, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  18% 208M/1.17G [00:07<00:13, 69.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  22% 256M/1.17G [00:08<00:09, 100MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  25% 288M/1.17G [00:08<00:07, 110MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  29% 336M/1.17G [00:08<00:05, 150MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  32% 368M/1.17G [00:08<00:04, 167MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  34% 400M/1.17G [00:08<00:04, 176MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  37% 432M/1.17G [00:09<00:04, 154MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  41% 480M/1.17G [00:09<00:03, 203MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  45% 528M/1.17G [00:09<00:03, 206MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  49% 576M/1.17G [00:09<00:02, 212MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  52% 608M/1.17G [00:09<00:02, 206MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  60% 704M/1.17G [00:09<00:01, 335MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  67% 784M/1.17G [00:10<00:01, 376MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  79% 928M/1.17G [00:10<00:00, 549MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin:  88% 1.02G/1.17G [00:10<00:00, 619MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00004.bin: 1.18GB [00:10, 112MB/s]                \n",
            " 67% 4/6 [02:22<01:01, 30.72s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:00<00:00, 29.4MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:01, 26.5MB/s]\n",
            " 83% 5/6 [02:24<00:20, 20.19s/it]\n",
            "unsloth.F16.gguf:   0% 0.00/16.1G [00:00<?, ?B/s]\u001b[A\n",
            "unsloth.F16.gguf:   0% 16.1M/16.1G [00:09<2:41:19, 1.66MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   0% 32.1M/16.1G [00:10<1:14:49, 3.57MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   0% 48.2M/16.1G [00:10<41:43, 6.40MB/s]  \u001b[A\n",
            "unsloth.F16.gguf:   0% 64.3M/16.1G [00:11<28:03, 9.50MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 80.3M/16.1G [00:11<22:47, 11.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 96.4M/16.1G [00:12<15:59, 16.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 112M/16.1G [00:12<12:33, 21.2MB/s] \u001b[A\n",
            "unsloth.F16.gguf:   1% 145M/16.1G [00:12<08:08, 32.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 161M/16.1G [00:13<07:03, 37.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 177M/16.1G [00:13<06:54, 38.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 193M/16.1G [00:13<05:49, 45.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 209M/16.1G [00:14<05:58, 44.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   1% 225M/16.1G [00:14<05:09, 51.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   2% 257M/16.1G [00:14<03:34, 73.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   2% 305M/16.1G [00:14<02:19, 113MB/s] \u001b[A\n",
            "unsloth.F16.gguf:   2% 321M/16.1G [00:14<02:15, 117MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   2% 337M/16.1G [00:15<02:39, 98.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   2% 386M/16.1G [00:15<01:57, 134MB/s] \u001b[A\n",
            "unsloth.F16.gguf:   3% 402M/16.1G [00:15<01:53, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   3% 434M/16.1G [00:15<02:34, 101MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   3% 450M/16.1G [00:15<02:25, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   3% 466M/16.1G [00:16<02:23, 109MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   3% 498M/16.1G [00:16<01:49, 142MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   3% 546M/16.1G [00:16<01:22, 188MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   4% 578M/16.1G [00:16<01:25, 181MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   4% 643M/16.1G [00:16<00:57, 268MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   4% 675M/16.1G [00:16<00:55, 279MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   4% 707M/16.1G [00:16<00:54, 280MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   5% 739M/16.1G [00:17<01:23, 183MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   5% 771M/16.1G [00:17<01:19, 193MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   5% 803M/16.1G [00:17<01:14, 205MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   5% 868M/16.1G [00:17<00:55, 275MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   6% 900M/16.1G [00:17<01:05, 230MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   6% 932M/16.1G [00:18<01:21, 186MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   6% 964M/16.1G [00:18<01:15, 199MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   7% 1.04G/16.1G [00:18<00:51, 294MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   7% 1.12G/16.1G [00:18<00:37, 396MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   7% 1.17G/16.1G [00:18<00:50, 298MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   8% 1.22G/16.1G [00:18<00:54, 270MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   8% 1.27G/16.1G [00:19<00:51, 286MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   8% 1.32G/16.1G [00:19<00:48, 302MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   9% 1.37G/16.1G [00:19<00:52, 278MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   9% 1.40G/16.1G [00:19<00:53, 275MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   9% 1.43G/16.1G [00:19<00:52, 280MB/s]\u001b[A\n",
            "unsloth.F16.gguf:   9% 1.46G/16.1G [00:19<01:03, 228MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  10% 1.53G/16.1G [00:20<00:54, 269MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  10% 1.56G/16.1G [00:20<00:52, 275MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  10% 1.59G/16.1G [00:20<00:59, 245MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  10% 1.66G/16.1G [00:20<01:03, 228MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  11% 1.69G/16.1G [00:21<01:26, 166MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  11% 1.72G/16.1G [00:21<01:50, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  11% 1.78G/16.1G [00:21<01:52, 127MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  11% 1.82G/16.1G [00:22<01:37, 147MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.85G/16.1G [00:22<01:29, 158MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.88G/16.1G [00:22<01:42, 139MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.91G/16.1G [00:22<01:54, 124MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.93G/16.1G [00:23<02:01, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.94G/16.1G [00:23<02:33, 91.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.96G/16.1G [00:23<02:37, 89.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  12% 1.99G/16.1G [00:23<01:54, 123MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  13% 2.02G/16.1G [00:23<01:34, 148MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.06G/16.1G [00:24<02:58, 78.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.07G/16.1G [00:26<07:39, 30.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.09G/16.1G [00:26<06:38, 35.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.11G/16.1G [00:27<06:34, 35.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.12G/16.1G [00:27<05:25, 42.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  13% 2.14G/16.1G [00:27<04:40, 49.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.17G/16.1G [00:27<03:06, 74.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.19G/16.1G [00:28<04:03, 57.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.20G/16.1G [00:28<03:38, 63.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.25G/16.1G [00:28<02:15, 102MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  14% 2.28G/16.1G [00:28<01:55, 119MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.30G/16.1G [00:28<01:57, 117MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  14% 2.31G/16.1G [00:28<01:58, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.35G/16.1G [00:29<02:26, 93.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.36G/16.1G [00:29<02:32, 89.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.38G/16.1G [00:29<02:32, 89.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.39G/16.1G [00:30<03:23, 67.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.43G/16.1G [00:30<04:06, 55.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.46G/16.1G [00:31<03:36, 62.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  15% 2.47G/16.1G [00:31<04:05, 55.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  16% 2.51G/16.1G [00:31<02:49, 80.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  16% 2.54G/16.1G [00:32<02:43, 82.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  16% 2.59G/16.1G [00:32<02:08, 105MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  16% 2.62G/16.1G [00:32<01:53, 119MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.65G/16.1G [00:33<02:00, 111MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.68G/16.1G [00:33<01:51, 120MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.70G/16.1G [00:33<01:54, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.73G/16.1G [00:33<01:41, 132MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.75G/16.1G [00:33<01:42, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.76G/16.1G [00:33<01:45, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  17% 2.78G/16.1G [00:34<02:19, 95.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  18% 2.83G/16.1G [00:34<01:36, 137MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  18% 2.86G/16.1G [00:34<02:04, 106MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  18% 2.88G/16.1G [00:34<01:57, 112MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  18% 2.91G/16.1G [00:35<01:44, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  18% 2.94G/16.1G [00:35<01:43, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  19% 2.99G/16.1G [00:35<01:14, 176MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  19% 3.02G/16.1G [00:35<01:12, 180MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  19% 3.05G/16.1G [00:36<01:40, 129MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  19% 3.10G/16.1G [00:36<01:14, 175MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  20% 3.13G/16.1G [00:36<01:12, 179MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  20% 3.18G/16.1G [00:36<01:19, 162MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  20% 3.23G/16.1G [00:36<01:03, 201MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  20% 3.28G/16.1G [00:37<01:15, 169MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  21% 3.31G/16.1G [00:37<01:15, 169MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  21% 3.34G/16.1G [00:37<01:32, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  21% 3.37G/16.1G [00:37<01:23, 151MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  21% 3.41G/16.1G [00:38<01:19, 159MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  21% 3.44G/16.1G [00:38<01:17, 163MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  22% 3.47G/16.1G [00:38<01:11, 176MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  22% 3.50G/16.1G [00:38<01:19, 158MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  22% 3.54G/16.1G [00:38<01:25, 146MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  22% 3.55G/16.1G [00:39<01:24, 148MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  22% 3.58G/16.1G [00:39<01:09, 179MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  23% 3.62G/16.1G [00:39<01:02, 199MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  23% 3.65G/16.1G [00:39<00:59, 208MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  23% 3.71G/16.1G [00:39<00:43, 286MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  23% 3.74G/16.1G [00:40<01:19, 155MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  24% 3.78G/16.1G [00:40<01:11, 171MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  24% 3.81G/16.1G [00:40<01:21, 151MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  24% 3.84G/16.1G [00:40<01:13, 167MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  24% 3.87G/16.1G [00:40<01:25, 143MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  24% 3.90G/16.1G [00:41<02:01, 100MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 3.94G/16.1G [00:41<01:55, 105MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 3.95G/16.1G [00:42<02:54, 69.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 3.97G/16.1G [00:42<02:50, 70.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 3.99G/16.1G [00:42<03:02, 66.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 4.00G/16.1G [00:42<02:41, 74.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 4.03G/16.1G [00:43<02:01, 99.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  25% 4.07G/16.1G [00:43<02:01, 98.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  26% 4.10G/16.1G [00:43<01:51, 108MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  26% 4.13G/16.1G [00:43<01:31, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  26% 4.15G/16.1G [00:44<02:18, 86.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  26% 4.16G/16.1G [00:44<02:14, 88.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  26% 4.19G/16.1G [00:44<01:57, 101MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  26% 4.23G/16.1G [00:45<02:15, 87.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  26% 4.24G/16.1G [00:45<02:04, 94.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  27% 4.29G/16.1G [00:45<01:31, 128MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  27% 4.31G/16.1G [00:45<01:42, 115MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  27% 4.32G/16.1G [00:45<01:36, 121MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  27% 4.34G/16.1G [00:46<01:55, 101MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  27% 4.39G/16.1G [00:46<01:12, 161MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  28% 4.42G/16.1G [00:46<02:08, 91.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  28% 4.45G/16.1G [00:47<02:19, 83.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  28% 4.50G/16.1G [00:47<01:43, 112MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  28% 4.52G/16.1G [00:47<01:41, 114MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  28% 4.53G/16.1G [00:47<02:09, 89.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  28% 4.56G/16.1G [00:48<02:21, 81.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.60G/16.1G [00:49<02:46, 68.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.61G/16.1G [00:49<02:32, 75.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.64G/16.1G [00:49<02:00, 94.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.66G/16.1G [00:49<02:34, 73.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.69G/16.1G [00:50<02:17, 82.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  29% 4.71G/16.1G [00:50<02:34, 73.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  30% 4.74G/16.1G [00:50<02:05, 90.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  30% 4.79G/16.1G [00:50<01:27, 129MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  30% 4.80G/16.1G [00:50<01:30, 124MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  30% 4.82G/16.1G [00:51<01:29, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  30% 4.87G/16.1G [00:51<01:14, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  31% 4.90G/16.1G [00:51<01:17, 145MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  31% 4.93G/16.1G [00:51<01:08, 163MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  31% 4.97G/16.1G [00:51<01:02, 177MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  31% 5.00G/16.1G [00:51<00:58, 191MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  31% 5.03G/16.1G [00:52<01:26, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  32% 5.08G/16.1G [00:52<01:06, 166MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  32% 5.11G/16.1G [00:52<01:07, 162MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  32% 5.14G/16.1G [00:53<01:11, 152MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  32% 5.19G/16.1G [00:53<01:04, 169MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.22G/16.1G [00:53<01:21, 133MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.25G/16.1G [00:53<01:08, 158MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.29G/16.1G [00:54<01:48, 99.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.30G/16.1G [00:54<02:09, 83.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.32G/16.1G [00:54<02:13, 80.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.33G/16.1G [00:55<02:04, 85.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.35G/16.1G [00:55<02:29, 71.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  33% 5.37G/16.1G [00:55<02:10, 82.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  34% 5.43G/16.1G [00:56<01:41, 104MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  34% 5.45G/16.1G [00:56<01:38, 108MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  34% 5.46G/16.1G [00:56<01:44, 102MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  34% 5.50G/16.1G [00:56<01:30, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  34% 5.51G/16.1G [00:56<01:28, 119MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  35% 5.56G/16.1G [00:56<00:58, 179MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  35% 5.59G/16.1G [00:57<01:18, 133MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  35% 5.62G/16.1G [00:57<01:10, 148MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  35% 5.66G/16.1G [00:57<01:03, 165MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  35% 5.69G/16.1G [00:57<01:22, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  36% 5.75G/16.1G [00:58<00:59, 173MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  36% 5.78G/16.1G [00:58<00:56, 181MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  36% 5.82G/16.1G [00:58<00:57, 179MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 5.87G/16.1G [00:58<00:52, 195MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 5.90G/16.1G [00:58<01:01, 164MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 5.93G/16.1G [00:59<01:07, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 5.96G/16.1G [00:59<01:53, 89.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 5.98G/16.1G [01:00<01:53, 89.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  37% 6.01G/16.1G [01:00<01:54, 87.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  38% 6.04G/16.1G [01:00<01:33, 108MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  38% 6.09G/16.1G [01:00<01:15, 133MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  38% 6.11G/16.1G [01:01<01:18, 127MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  38% 6.17G/16.1G [01:01<00:49, 200MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  39% 6.20G/16.1G [01:01<00:54, 180MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  39% 6.23G/16.1G [01:01<01:21, 121MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  39% 6.28G/16.1G [01:02<01:08, 142MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  39% 6.32G/16.1G [01:03<02:20, 69.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  39% 6.33G/16.1G [01:03<02:09, 75.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  40% 6.35G/16.1G [01:03<02:00, 80.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  40% 6.38G/16.1G [01:03<01:57, 82.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  40% 6.41G/16.1G [01:04<01:40, 96.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  40% 6.43G/16.1G [01:04<01:39, 97.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  40% 6.48G/16.1G [01:04<01:04, 150MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  41% 6.52G/16.1G [01:04<00:48, 195MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  41% 6.57G/16.1G [01:04<00:42, 225MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  41% 6.60G/16.1G [01:05<01:00, 157MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  41% 6.65G/16.1G [01:05<00:49, 191MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.68G/16.1G [01:05<00:54, 172MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.72G/16.1G [01:05<00:56, 166MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.75G/16.1G [01:05<00:50, 183MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.78G/16.1G [01:06<01:58, 78.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.80G/16.1G [01:06<01:49, 84.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  42% 6.81G/16.1G [01:07<01:54, 81.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.83G/16.1G [01:07<02:36, 59.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.86G/16.1G [01:07<01:58, 77.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.88G/16.1G [01:08<02:14, 68.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.89G/16.1G [01:08<02:19, 66.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.91G/16.1G [01:08<02:17, 66.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.93G/16.1G [01:08<02:02, 74.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  43% 6.94G/16.1G [01:09<01:46, 85.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  44% 6.99G/16.1G [01:09<01:11, 126MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  44% 7.01G/16.1G [01:09<01:44, 86.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  44% 7.04G/16.1G [01:09<01:24, 107MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  44% 7.05G/16.1G [01:10<01:31, 98.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  44% 7.09G/16.1G [01:10<01:21, 111MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  44% 7.12G/16.1G [01:10<01:26, 104MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  45% 7.17G/16.1G [01:10<01:08, 131MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  45% 7.18G/16.1G [01:10<01:05, 135MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  45% 7.20G/16.1G [01:11<01:11, 125MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  45% 7.25G/16.1G [01:11<01:05, 135MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  45% 7.28G/16.1G [01:11<01:02, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  46% 7.34G/16.1G [01:11<00:46, 189MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  46% 7.38G/16.1G [01:12<01:18, 111MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  46% 7.42G/16.1G [01:12<00:59, 146MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.47G/16.1G [01:12<00:49, 175MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.50G/16.1G [01:13<01:13, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.54G/16.1G [01:14<01:38, 86.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.55G/16.1G [01:14<01:34, 89.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.57G/16.1G [01:14<01:39, 85.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  47% 7.60G/16.1G [01:14<01:24, 101MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  48% 7.65G/16.1G [01:14<01:04, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  48% 7.68G/16.1G [01:14<00:55, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  48% 7.71G/16.1G [01:15<00:50, 166MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  48% 7.75G/16.1G [01:15<00:51, 162MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  48% 7.78G/16.1G [01:15<00:51, 160MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  49% 7.81G/16.1G [01:15<01:11, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  49% 7.84G/16.1G [01:16<01:01, 135MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  49% 7.87G/16.1G [01:16<01:04, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  49% 7.89G/16.1G [01:16<01:02, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  49% 7.94G/16.1G [01:16<00:44, 181MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 7.97G/16.1G [01:17<00:57, 142MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 8.00G/16.1G [01:17<01:09, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 8.03G/16.1G [01:17<01:14, 109MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 8.05G/16.1G [01:17<01:15, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 8.07G/16.1G [01:18<01:11, 111MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  50% 8.08G/16.1G [01:18<01:41, 78.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  51% 8.11G/16.1G [01:18<01:14, 106MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  51% 8.13G/16.1G [01:18<01:32, 85.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  51% 8.16G/16.1G [01:19<01:18, 101MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  51% 8.20G/16.1G [01:19<01:06, 118MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  51% 8.24G/16.1G [01:19<00:45, 170MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  52% 8.28G/16.1G [01:19<00:54, 144MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  52% 8.31G/16.1G [01:20<01:04, 120MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  52% 8.34G/16.1G [01:20<00:55, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  52% 8.37G/16.1G [01:21<01:40, 76.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  52% 8.42G/16.1G [01:21<01:12, 106MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  53% 8.47G/16.1G [01:21<01:02, 123MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  53% 8.50G/16.1G [01:22<01:18, 96.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  53% 8.53G/16.1G [01:22<01:06, 113MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  53% 8.56G/16.1G [01:22<01:08, 109MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  54% 8.61G/16.1G [01:22<00:48, 152MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  54% 8.65G/16.1G [01:22<00:43, 173MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  54% 8.69G/16.1G [01:23<00:39, 186MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  54% 8.73G/16.1G [01:23<00:39, 185MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  55% 8.76G/16.1G [01:23<01:11, 103MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  55% 8.79G/16.1G [01:24<01:13, 98.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  55% 8.84G/16.1G [01:24<00:54, 132MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  55% 8.87G/16.1G [01:24<01:06, 109MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  55% 8.90G/16.1G [01:25<01:14, 96.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  56% 8.92G/16.1G [01:25<01:40, 71.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  56% 8.97G/16.1G [01:26<01:21, 86.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  56% 9.00G/16.1G [01:26<01:18, 89.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  56% 9.01G/16.1G [01:26<01:29, 79.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  56% 9.06G/16.1G [01:27<01:20, 86.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  57% 9.11G/16.1G [01:27<01:02, 112MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  57% 9.13G/16.1G [01:27<01:10, 98.2MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  57% 9.16G/16.1G [01:28<01:00, 114MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  57% 9.18G/16.1G [01:28<00:59, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  57% 9.21G/16.1G [01:28<00:46, 147MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  58% 9.24G/16.1G [01:28<00:42, 161MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  58% 9.27G/16.1G [01:28<01:07, 101MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  58% 9.29G/16.1G [01:29<01:22, 82.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  58% 9.34G/16.1G [01:29<00:59, 112MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  58% 9.35G/16.1G [01:29<00:59, 113MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  58% 9.38G/16.1G [01:29<00:51, 130MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  59% 9.42G/16.1G [01:30<00:54, 123MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  59% 9.45G/16.1G [01:30<00:45, 146MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  59% 9.48G/16.1G [01:30<00:38, 172MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  59% 9.51G/16.1G [01:30<00:38, 170MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  59% 9.54G/16.1G [01:30<00:33, 197MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  60% 9.58G/16.1G [01:30<00:40, 162MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  60% 9.61G/16.1G [01:31<01:14, 87.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  60% 9.64G/16.1G [01:31<01:04, 99.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  60% 9.67G/16.1G [01:32<01:01, 103MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  60% 9.71G/16.1G [01:32<00:59, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  61% 9.74G/16.1G [01:32<00:52, 121MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  61% 9.77G/16.1G [01:32<00:44, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  61% 9.80G/16.1G [01:33<00:49, 127MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  61% 9.83G/16.1G [01:33<00:43, 145MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  61% 9.87G/16.1G [01:33<00:37, 165MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  62% 9.91G/16.1G [01:33<00:34, 178MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  62% 9.95G/16.1G [01:33<00:38, 158MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  62% 9.99G/16.1G [01:34<00:39, 153MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  62% 10.0G/16.1G [01:34<00:44, 136MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  63% 10.0G/16.1G [01:34<00:45, 132MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  63% 10.1G/16.1G [01:35<00:55, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  63% 10.1G/16.1G [01:35<00:42, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  63% 10.2G/16.1G [01:35<00:48, 121MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  63% 10.2G/16.1G [01:35<00:47, 125MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  64% 10.2G/16.1G [01:36<00:45, 129MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  64% 10.3G/16.1G [01:36<00:43, 135MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  64% 10.3G/16.1G [01:36<00:41, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  64% 10.3G/16.1G [01:36<00:35, 162MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  65% 10.4G/16.1G [01:36<00:26, 214MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  65% 10.4G/16.1G [01:37<01:03, 88.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  65% 10.4G/16.1G [01:38<01:11, 79.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  65% 10.5G/16.1G [01:38<01:00, 92.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  66% 10.5G/16.1G [01:38<00:52, 105MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  66% 10.5G/16.1G [01:39<00:56, 98.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  66% 10.6G/16.1G [01:39<00:49, 111MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  66% 10.6G/16.1G [01:39<00:52, 104MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  66% 10.6G/16.1G [01:39<00:58, 94.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  66% 10.6G/16.1G [01:40<01:05, 82.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  66% 10.7G/16.1G [01:40<00:53, 102MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  67% 10.7G/16.1G [01:40<00:43, 124MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  67% 10.8G/16.1G [01:40<00:31, 167MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  67% 10.8G/16.1G [01:41<00:37, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  67% 10.8G/16.1G [01:41<00:37, 142MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  67% 10.8G/16.1G [01:41<00:54, 95.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  68% 10.9G/16.1G [01:41<00:45, 114MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  68% 10.9G/16.1G [01:42<00:40, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  68% 10.9G/16.1G [01:42<00:39, 131MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  68% 10.9G/16.1G [01:42<00:43, 119MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  68% 11.0G/16.1G [01:42<00:58, 88.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  68% 11.0G/16.1G [01:43<00:59, 85.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.0G/16.1G [01:43<00:46, 108MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  69% 11.0G/16.1G [01:43<00:44, 114MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.1G/16.1G [01:43<00:46, 108MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.1G/16.1G [01:44<00:41, 120MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.1G/16.1G [01:44<00:39, 125MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.1G/16.1G [01:44<00:40, 122MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  69% 11.2G/16.1G [01:44<01:12, 67.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.2G/16.1G [01:45<00:54, 89.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.2G/16.1G [01:45<01:00, 80.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.2G/16.1G [01:45<01:00, 80.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.2G/16.1G [01:45<01:06, 72.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.2G/16.1G [01:46<01:28, 54.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.3G/16.1G [01:46<01:13, 65.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  70% 11.3G/16.1G [01:46<00:48, 98.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  71% 11.3G/16.1G [01:46<00:36, 130MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  71% 11.4G/16.1G [01:46<00:29, 160MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  71% 11.4G/16.1G [01:47<00:36, 127MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  71% 11.4G/16.1G [01:47<00:47, 96.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  71% 11.5G/16.1G [01:47<00:40, 115MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  72% 11.5G/16.1G [01:48<00:42, 109MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  72% 11.5G/16.1G [01:48<00:35, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  72% 11.5G/16.1G [01:48<00:37, 120MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  72% 11.6G/16.1G [01:48<00:29, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  72% 11.6G/16.1G [01:48<00:27, 160MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.6G/16.1G [01:49<00:32, 137MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.7G/16.1G [01:49<00:40, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.7G/16.1G [01:49<00:41, 105MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.7G/16.1G [01:50<00:43, 100MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.7G/16.1G [01:50<00:41, 104MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  73% 11.8G/16.1G [01:50<00:26, 160MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  74% 11.8G/16.1G [01:50<00:27, 156MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  74% 11.9G/16.1G [01:50<00:23, 181MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  74% 11.9G/16.1G [01:51<00:29, 143MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  75% 12.0G/16.1G [01:51<00:19, 205MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  75% 12.0G/16.1G [01:51<00:19, 210MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  75% 12.0G/16.1G [01:51<00:20, 200MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  75% 12.1G/16.1G [01:52<00:32, 125MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  75% 12.1G/16.1G [01:52<00:27, 146MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  76% 12.1G/16.1G [01:52<00:26, 151MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  76% 12.2G/16.1G [01:52<00:26, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  76% 12.2G/16.1G [01:53<00:37, 103MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  76% 12.2G/16.1G [01:53<00:39, 97.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  76% 12.3G/16.1G [01:53<00:30, 124MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  76% 12.3G/16.1G [01:53<00:34, 111MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.3G/16.1G [01:54<00:35, 106MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.3G/16.1G [01:54<00:35, 106MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.3G/16.1G [01:54<00:34, 110MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.4G/16.1G [01:54<00:26, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.4G/16.1G [01:54<00:21, 170MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  77% 12.4G/16.1G [01:54<00:24, 147MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  78% 12.5G/16.1G [01:54<00:21, 172MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  78% 12.5G/16.1G [01:55<00:42, 85.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  78% 12.5G/16.1G [01:55<00:32, 110MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  78% 12.6G/16.1G [01:56<00:22, 153MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  78% 12.6G/16.1G [01:56<00:22, 152MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  79% 12.6G/16.1G [01:56<00:32, 106MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  79% 12.7G/16.1G [01:57<00:45, 73.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  79% 12.7G/16.1G [01:57<00:33, 99.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  79% 12.8G/16.1G [01:58<00:28, 118MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  80% 12.8G/16.1G [01:58<00:28, 116MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  80% 12.8G/16.1G [01:58<00:26, 122MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  80% 12.9G/16.1G [01:58<00:30, 106MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  80% 12.9G/16.1G [01:59<00:35, 90.3MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  80% 12.9G/16.1G [01:59<00:27, 116MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  81% 13.0G/16.1G [01:59<00:31, 99.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  81% 13.0G/16.1G [02:00<00:26, 117MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  81% 13.0G/16.1G [02:00<00:31, 98.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  81% 13.0G/16.1G [02:00<00:33, 90.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  81% 13.1G/16.1G [02:00<00:27, 110MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  82% 13.1G/16.1G [02:01<00:23, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  82% 13.1G/16.1G [02:01<00:23, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  82% 13.2G/16.1G [02:01<00:23, 122MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  82% 13.2G/16.1G [02:01<00:23, 122MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  82% 13.2G/16.1G [02:01<00:25, 115MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  82% 13.2G/16.1G [02:02<00:37, 74.9MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  83% 13.3G/16.1G [02:03<00:35, 79.6MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  83% 13.3G/16.1G [02:03<00:35, 78.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  83% 13.3G/16.1G [02:03<00:36, 76.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  83% 13.3G/16.1G [02:03<00:25, 106MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  83% 13.4G/16.1G [02:04<00:25, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  83% 13.4G/16.1G [02:04<00:24, 108MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  84% 13.4G/16.1G [02:04<00:22, 117MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  84% 13.4G/16.1G [02:04<00:23, 113MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  84% 13.5G/16.1G [02:04<00:21, 120MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  84% 13.5G/16.1G [02:05<00:15, 164MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  84% 13.6G/16.1G [02:05<00:15, 161MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  85% 13.6G/16.1G [02:05<00:13, 184MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  85% 13.6G/16.1G [02:05<00:16, 145MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  85% 13.7G/16.1G [02:06<00:15, 150MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  85% 13.7G/16.1G [02:06<00:16, 147MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  85% 13.7G/16.1G [02:06<00:16, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.8G/16.1G [02:06<00:17, 131MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.8G/16.1G [02:06<00:18, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.8G/16.1G [02:07<00:22, 103MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.8G/16.1G [02:07<00:17, 129MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.8G/16.1G [02:07<00:17, 127MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.9G/16.1G [02:07<00:15, 141MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  86% 13.9G/16.1G [02:07<00:17, 128MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  87% 13.9G/16.1G [02:07<00:10, 197MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  87% 14.0G/16.1G [02:07<00:09, 222MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  87% 14.0G/16.1G [02:08<00:14, 142MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  87% 14.0G/16.1G [02:08<00:13, 147MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  88% 14.1G/16.1G [02:08<00:13, 154MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  88% 14.1G/16.1G [02:09<00:14, 138MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  88% 14.1G/16.1G [02:09<00:12, 157MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  88% 14.2G/16.1G [02:09<00:10, 178MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  88% 14.2G/16.1G [02:09<00:10, 186MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.2G/16.1G [02:09<00:10, 169MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.3G/16.1G [02:10<00:14, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.3G/16.1G [02:10<00:16, 107MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.3G/16.1G [02:11<00:18, 95.8MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.3G/16.1G [02:11<00:20, 82.7MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  89% 14.4G/16.1G [02:11<00:18, 90.0MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  90% 14.4G/16.1G [02:11<00:20, 82.1MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  90% 14.4G/16.1G [02:12<00:27, 61.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  90% 14.4G/16.1G [02:12<00:23, 71.4MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  90% 14.5G/16.1G [02:12<00:13, 119MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  90% 14.5G/16.1G [02:12<00:17, 90.5MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  90% 14.5G/16.1G [02:13<00:14, 105MB/s] \u001b[A\n",
            "unsloth.F16.gguf:  91% 14.6G/16.1G [02:13<00:07, 206MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  91% 14.6G/16.1G [02:13<00:07, 198MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  91% 14.7G/16.1G [02:13<00:07, 177MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  91% 14.7G/16.1G [02:13<00:09, 152MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  92% 14.7G/16.1G [02:14<00:09, 140MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  92% 14.8G/16.1G [02:14<00:07, 180MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  92% 14.8G/16.1G [02:14<00:06, 189MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  92% 14.8G/16.1G [02:14<00:06, 198MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  93% 14.9G/16.1G [02:14<00:06, 180MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  93% 14.9G/16.1G [02:14<00:07, 165MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  93% 14.9G/16.1G [02:15<00:08, 131MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  93% 14.9G/16.1G [02:15<00:08, 126MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  93% 15.0G/16.1G [02:15<00:06, 164MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  94% 15.1G/16.1G [02:15<00:04, 216MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  94% 15.1G/16.1G [02:16<00:04, 239MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  94% 15.1G/16.1G [02:16<00:04, 200MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  95% 15.2G/16.1G [02:16<00:03, 238MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  95% 15.2G/16.1G [02:16<00:02, 283MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  95% 15.3G/16.1G [02:16<00:03, 260MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  95% 15.3G/16.1G [02:16<00:02, 292MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  96% 15.4G/16.1G [02:16<00:01, 363MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  96% 15.5G/16.1G [02:17<00:01, 462MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  97% 15.6G/16.1G [02:17<00:00, 588MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  98% 15.7G/16.1G [02:17<00:00, 582MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  98% 15.7G/16.1G [02:17<00:00, 587MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  98% 15.8G/16.1G [02:17<00:00, 540MB/s]\u001b[A\n",
            "unsloth.F16.gguf:  99% 15.9G/16.1G [02:17<00:00, 571MB/s]\u001b[A\n",
            "unsloth.F16.gguf: 16.1GB [02:18, 116MB/s]                \n",
            "100% 6/6 [04:43<00:00, 47.21s/it]\n",
            "https://huggingface.co/gcc009/llama3-inst-rd_phenotype_disease-GGUF/tree/main/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vju8_Z23KcO"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d05508998bea4d6389f68a7bcc04050b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d3a24da4335490aa205ac80324d52f7",
              "IPY_MODEL_6930248394e345f7b130784c04d43341",
              "IPY_MODEL_6a1c0cb8e59e4691944920b05dbff6a1"
            ],
            "layout": "IPY_MODEL_a71d05451295413488012326297b582e"
          }
        },
        "5d3a24da4335490aa205ac80324d52f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_557c156d617742979302a02a847c59d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de253d5d3e014395870cfe3c5d31635c",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "6930248394e345f7b130784c04d43341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cd2b677841417e9155086ee4673180",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa9ee2cb238b4a2382e07b4a6a30d7b0",
            "value": 5702745860
          }
        },
        "6a1c0cb8e59e4691944920b05dbff6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13634c85a5f471a9dc6eab5584c4f5a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bb8e838720854b49b9b7b6c85493ca96",
            "value": "‚Äá5.70G/5.70G‚Äá[00:43&lt;00:00,‚Äá329MB/s]"
          }
        },
        "a71d05451295413488012326297b582e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557c156d617742979302a02a847c59d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de253d5d3e014395870cfe3c5d31635c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34cd2b677841417e9155086ee4673180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9ee2cb238b4a2382e07b4a6a30d7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e13634c85a5f471a9dc6eab5584c4f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8e838720854b49b9b7b6c85493ca96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99d3c17ff5754d329f9d443b70774f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b3e9a1964a34ef9bb775a8983c25a56",
              "IPY_MODEL_409e341c45f64b0ea9c6abd60dde4bfb",
              "IPY_MODEL_05404ab82ade48e892aa8832e7144dec"
            ],
            "layout": "IPY_MODEL_b7f658a74a334bc1a3ec68a4d1fb27b5"
          }
        },
        "4b3e9a1964a34ef9bb775a8983c25a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bfca92d3c744f00af8e732017fa9fbe",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fcaf15df282841d68749cc5040ea648d",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "409e341c45f64b0ea9c6abd60dde4bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2174a58002845299b066283ab3d2d8c",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35bc5a363e804c79bd16939dbf1ff35b",
            "value": 220
          }
        },
        "05404ab82ade48e892aa8832e7144dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1c806451724933af6dfe9fcc28b7ea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_48833bda51fb420888ca817ca9d79c36",
            "value": "‚Äá220/220‚Äá[00:00&lt;00:00,‚Äá8.78kB/s]"
          }
        },
        "b7f658a74a334bc1a3ec68a4d1fb27b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfca92d3c744f00af8e732017fa9fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcaf15df282841d68749cc5040ea648d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2174a58002845299b066283ab3d2d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35bc5a363e804c79bd16939dbf1ff35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a1c806451724933af6dfe9fcc28b7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48833bda51fb420888ca817ca9d79c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53b5e1006c7b4b4e9ffde2c40fcfb920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc07955dc92d4ab7a9cc25c5e2be31ed",
              "IPY_MODEL_53d48c94a6954779a2679bbf767a95b9",
              "IPY_MODEL_287b4ae6701d4e93a4d36c8f9c2cfc4c"
            ],
            "layout": "IPY_MODEL_0e60b734371c43eab0c28a76115b3378"
          }
        },
        "bc07955dc92d4ab7a9cc25c5e2be31ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b69708334dd24e46913029e5ecb12d96",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_63462a981a1c46aeb6dc79be659761c3",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "53d48c94a6954779a2679bbf767a95b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a981c81081e94657ab780ce1cccdfa5d",
            "max": 51052,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3417e82fb6b14a16bfb726b19e364044",
            "value": 51052
          }
        },
        "287b4ae6701d4e93a4d36c8f9c2cfc4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101e27567146455d88ca46575e13bdae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6d70d25ce3ce48c6bda6b4c12c91be59",
            "value": "‚Äá51.1k/51.1k‚Äá[00:00&lt;00:00,‚Äá2.75MB/s]"
          }
        },
        "0e60b734371c43eab0c28a76115b3378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69708334dd24e46913029e5ecb12d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63462a981a1c46aeb6dc79be659761c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a981c81081e94657ab780ce1cccdfa5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3417e82fb6b14a16bfb726b19e364044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "101e27567146455d88ca46575e13bdae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d70d25ce3ce48c6bda6b4c12c91be59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2773929ff3104db78c79ba5d1e536668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a37e38f774e4d70a3243510ae99c730",
              "IPY_MODEL_15273559898c45aaa6da45274db74c4e",
              "IPY_MODEL_8d00b41544db4b609b4a4f9202fb3ce4"
            ],
            "layout": "IPY_MODEL_a5dd7d3bef5b4e718dddfd27041688eb"
          }
        },
        "3a37e38f774e4d70a3243510ae99c730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b171569c3e8f4b03bdda824e16b21969",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c44b3feb513484e9dc7bdb887bc123d",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "15273559898c45aaa6da45274db74c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282a0b3844d9421b8b7ed0011aeb9de7",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbbce248d1e3452fa012a77a2fd4f6d0",
            "value": 9085698
          }
        },
        "8d00b41544db4b609b4a4f9202fb3ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f56bb51759fc41d0bb9dc35035a9cecf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3389a85b593744c880ad399bd2a165af",
            "value": "‚Äá9.09M/9.09M‚Äá[00:00&lt;00:00,‚Äá10.4MB/s]"
          }
        },
        "a5dd7d3bef5b4e718dddfd27041688eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b171569c3e8f4b03bdda824e16b21969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c44b3feb513484e9dc7bdb887bc123d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "282a0b3844d9421b8b7ed0011aeb9de7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbce248d1e3452fa012a77a2fd4f6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f56bb51759fc41d0bb9dc35035a9cecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3389a85b593744c880ad399bd2a165af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c944aeb45fdc4f61a8424c4a0f44a8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a44daaccd6df4063abbf5b5e18c79ae2",
              "IPY_MODEL_7df7c04604464b638bf3cf534fac913a",
              "IPY_MODEL_0efa81beaf134d25ace6b25e8ae60a8c"
            ],
            "layout": "IPY_MODEL_931aafc86fde496b98ca64038d3b9a7b"
          }
        },
        "a44daaccd6df4063abbf5b5e18c79ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95e7fd9d87d4f418b90155904c2935d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fffbedd22dbb467eae8f9c05d204c3e7",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "7df7c04604464b638bf3cf534fac913a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7353fb15d3d94fa6bd985864d62c6f08",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aabca9a232d4a7c900763fa98e348b1",
            "value": 345
          }
        },
        "0efa81beaf134d25ace6b25e8ae60a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d31dbd19144d88829f50718fc6e097",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c4775896274d4a04b1a7f25b157e4d9a",
            "value": "‚Äá345/345‚Äá[00:00&lt;00:00,‚Äá27.1kB/s]"
          }
        },
        "931aafc86fde496b98ca64038d3b9a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95e7fd9d87d4f418b90155904c2935d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffbedd22dbb467eae8f9c05d204c3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7353fb15d3d94fa6bd985864d62c6f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aabca9a232d4a7c900763fa98e348b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4d31dbd19144d88829f50718fc6e097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4775896274d4a04b1a7f25b157e4d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39330006fe1f411c828b181e570974f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_121631d20ad54400b573be72327a6163",
              "IPY_MODEL_a996ba3ebe674ad68b952582de76608d",
              "IPY_MODEL_d3cff037bd6b4635a64988f33413f350"
            ],
            "layout": "IPY_MODEL_dcdfe1a778ca4c40b8ed0e3143f78ad7"
          }
        },
        "121631d20ad54400b573be72327a6163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee39dcf11fa748e3987ef5e9fdb794ce",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_479989b277f14246b56f37ad0b06123d",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá"
          }
        },
        "a996ba3ebe674ad68b952582de76608d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df3bed2c278472cb044a052ba587d92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a805eb4fd46c4e48856ee100d06e6e86",
            "value": 1
          }
        },
        "d3cff037bd6b4635a64988f33413f350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bf5d4983494c2cb2b04e5c6807381b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f8974ab5a7d74c3a8422a29fc8755c80",
            "value": "‚Äá4240/0‚Äá[00:00&lt;00:00,‚Äá24850.83‚Äáexamples/s]"
          }
        },
        "dcdfe1a778ca4c40b8ed0e3143f78ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee39dcf11fa748e3987ef5e9fdb794ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479989b277f14246b56f37ad0b06123d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df3bed2c278472cb044a052ba587d92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a805eb4fd46c4e48856ee100d06e6e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37bf5d4983494c2cb2b04e5c6807381b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8974ab5a7d74c3a8422a29fc8755c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b18177591f4eef974600f97151b0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2db7d0851bc54df1906578cfaf0b368a",
              "IPY_MODEL_ff33be2f36484c64b3d1d38e3405d327",
              "IPY_MODEL_3d3f3bce48ce4bcdb499f3f28c975f94"
            ],
            "layout": "IPY_MODEL_7216def0fcd947bfac726589cf170116"
          }
        },
        "2db7d0851bc54df1906578cfaf0b368a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9cdf5a8ddb74ccdb52bb6a5b789f2e9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4fcc333e33044c38a804a9054ffbd503",
            "value": "Map:‚Äá100%"
          }
        },
        "ff33be2f36484c64b3d1d38e3405d327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf1a8ef845d4224a739d0e7487af946",
            "max": 4240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f0560006cc04eb696e11fe99721789f",
            "value": 4240
          }
        },
        "3d3f3bce48ce4bcdb499f3f28c975f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00bfea975a840d89a471e4bbe9ac6da",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_849f7342338a41a89169318dd12edb20",
            "value": "‚Äá4240/4240‚Äá[00:00&lt;00:00,‚Äá60837.55‚Äáexamples/s]"
          }
        },
        "7216def0fcd947bfac726589cf170116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9cdf5a8ddb74ccdb52bb6a5b789f2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcc333e33044c38a804a9054ffbd503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf1a8ef845d4224a739d0e7487af946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0560006cc04eb696e11fe99721789f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f00bfea975a840d89a471e4bbe9ac6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849f7342338a41a89169318dd12edb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf14bf550b91492e9494315fec9396dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9edbab43a9b84850979193f47d7784f8",
              "IPY_MODEL_4e8117416a7444ccbd425c616535ac2a",
              "IPY_MODEL_edf468dab1f044b9acaa7f77b6184baf"
            ],
            "layout": "IPY_MODEL_f9ed5cebdc714be1bf342c9fe8732fc6"
          }
        },
        "9edbab43a9b84850979193f47d7784f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79bc8fb260e14ac4a3b8a4f2a39579c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_86b0f908024b40f1ac6efd6bc6a41536",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "4e8117416a7444ccbd425c616535ac2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7b0af4b5ec4af09f4718c42407cfba",
            "max": 4240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_282b2ede643f47cfa4698ed6eacbde7a",
            "value": 4240
          }
        },
        "edf468dab1f044b9acaa7f77b6184baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8d6b180a5e140558d69094da7b50b67",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c53f064c945490a95cf329a4f91158c",
            "value": "‚Äá4240/4240‚Äá[00:04&lt;00:00,‚Äá1432.43‚Äáexamples/s]"
          }
        },
        "f9ed5cebdc714be1bf342c9fe8732fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79bc8fb260e14ac4a3b8a4f2a39579c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b0f908024b40f1ac6efd6bc6a41536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7b0af4b5ec4af09f4718c42407cfba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282b2ede643f47cfa4698ed6eacbde7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8d6b180a5e140558d69094da7b50b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c53f064c945490a95cf329a4f91158c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}